                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.75#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.75#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.75#

               Core t (s)   Wall t (s)        (%)
       Time:     2945.165     2945.165      100.0
                         49:05
                 (ns/day)    (hour/ns)
Performance:        4.400        5.454

GROMACS reminds you: "Don't You Wish You Never Met Her, Dirty Blue Gene?" (Captain Beefheart)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2917806.251406      task-clock (msec)         #    0.990 CPUs utilized          
           302,609      context-switches          #    0.104 K/sec                  
            14,868      cpu-migrations            #    0.005 K/sec                  
           178,928      page-faults               #    0.061 K/sec                  
 6,967,045,374,792      cycles                    #    2.388 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,137,741,029,760      instructions              #    1.89  insns per cycle        
   260,723,611,998      branches                  #   89.356 M/sec                  
     4,991,558,841      branch-misses             #    1.91% of all branches        

    2946.019546434 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.76#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.76#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.76#

               Core t (s)   Wall t (s)        (%)
       Time:     2960.221     2960.221      100.0
                         49:20
                 (ns/day)    (hour/ns)
Performance:        4.378        5.482

GROMACS reminds you: "Sisters Have Always Fascinated Me" (Speech)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2932325.805235      task-clock (msec)         #    0.990 CPUs utilized          
           303,982      context-switches          #    0.104 K/sec                  
            15,257      cpu-migrations            #    0.005 K/sec                  
           152,326      page-faults               #    0.052 K/sec                  
 6,980,376,958,671      cycles                    #    2.380 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,337,815,745,858      instructions              #    1.91  insns per cycle        
   257,855,712,579      branches                  #   87.936 M/sec                  
     5,081,446,626      branch-misses             #    1.97% of all branches        

    2960.994977173 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.77#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.77#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.1#

               Core t (s)   Wall t (s)        (%)
       Time:     2934.600     2934.600      100.0
                         48:54
                 (ns/day)    (hour/ns)
Performance:        4.416        5.434

GROMACS reminds you: "Erwin with his psi can do / Calculations quite a few. / But one thing has not been seen / Just what psi really mean." (Felix Bloch)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2907351.296891      task-clock (msec)         #    0.990 CPUs utilized          
           301,387      context-switches          #    0.104 K/sec                  
            14,232      cpu-migrations            #    0.005 K/sec                  
           210,718      page-faults               #    0.072 K/sec                  
 6,950,185,231,276      cycles                    #    2.391 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,174,720,789,839      instructions              #    1.90  insns per cycle        
   237,686,968,729      branches                  #   81.754 M/sec                  
     5,128,057,953      branch-misses             #    2.16% of all branches        

    2935.418287398 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.1#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.1#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.2#

               Core t (s)   Wall t (s)        (%)
       Time:     2922.666     2922.666      100.0
                         48:42
                 (ns/day)    (hour/ns)
Performance:        4.434        5.412

GROMACS reminds you: "I like to wait, then I feel like I do something" (Carl Caleman)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2896101.930295      task-clock (msec)         #    0.991 CPUs utilized          
           299,972      context-switches          #    0.104 K/sec                  
            14,206      cpu-migrations            #    0.005 K/sec                  
           169,985      page-faults               #    0.059 K/sec                  
 6,915,397,173,281      cycles                    #    2.388 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
12,992,965,010,374      instructions              #    1.88  insns per cycle        
   232,537,690,295      branches                  #   80.293 M/sec                  
     4,933,623,522      branch-misses             #    2.12% of all branches        

    2923.477833579 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.2#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.2#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.3#

               Core t (s)   Wall t (s)        (%)
       Time:     2941.446     2941.446      100.0
                         49:01
                 (ns/day)    (hour/ns)
Performance:        4.406        5.447

GROMACS reminds you: "May the Force Be With You" (Star Wars)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2913695.613490      task-clock (msec)         #    0.990 CPUs utilized          
           301,310      context-switches          #    0.103 K/sec                  
            14,744      cpu-migrations            #    0.005 K/sec                  
           170,155      page-faults               #    0.058 K/sec                  
 6,937,950,262,985      cycles                    #    2.381 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,174,251,975,917      instructions              #    1.90  insns per cycle        
   237,761,016,340      branches                  #   81.601 M/sec                  
     5,124,887,390      branch-misses             #    2.16% of all branches        

    2942.193413919 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.3#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.3#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.4#

               Core t (s)   Wall t (s)        (%)
       Time:     2926.876     2926.876      100.0
                         48:46
                 (ns/day)    (hour/ns)
Performance:        4.428        5.420

GROMACS reminds you: "I Ripped the Cord Right Out Of the Phone" (Capt. Beefheart)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2899043.669463      task-clock (msec)         #    0.990 CPUs utilized          
           300,673      context-switches          #    0.104 K/sec                  
            14,059      cpu-migrations            #    0.005 K/sec                  
           183,769      page-faults               #    0.063 K/sec                  
 6,909,586,058,030      cycles                    #    2.383 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,012,068,973,264      instructions              #    1.88  insns per cycle        
   234,717,679,288      branches                  #   80.964 M/sec                  
     5,332,367,276      branch-misses             #    2.27% of all branches        

    2927.649703629 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.4#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.4#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.5#

               Core t (s)   Wall t (s)        (%)
       Time:     2920.025     2920.025      100.0
                         48:40
                 (ns/day)    (hour/ns)
Performance:        4.438        5.407

GROMACS reminds you: "Humbug! Most things free-born will submit to anything for a salary" (Mr. Rochester in Jane Eyre by Charlotte Bronte)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2892666.866437      task-clock (msec)         #    0.990 CPUs utilized          
           299,405      context-switches          #    0.104 K/sec                  
            13,855      cpu-migrations            #    0.005 K/sec                  
           144,616      page-faults               #    0.050 K/sec                  
 6,908,900,445,580      cycles                    #    2.388 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
12,993,078,463,963      instructions              #    1.88  insns per cycle        
   232,278,681,737      branches                  #   80.299 M/sec                  
     4,944,885,251      branch-misses             #    2.13% of all branches        

    2920.780984889 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.5#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.5#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.6#

               Core t (s)   Wall t (s)        (%)
       Time:     2936.754     2936.754      100.0
                         48:56
                 (ns/day)    (hour/ns)
Performance:        4.413        5.438

GROMACS reminds you: "You fight, work, sweat, nearly kill yourself, sometimes you do kill yourself, trying to accomplish something - and you can't." (Joseph Conrad)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2909260.718669      task-clock (msec)         #    0.990 CPUs utilized          
           301,726      context-switches          #    0.104 K/sec                  
            14,135      cpu-migrations            #    0.005 K/sec                  
           207,757      page-faults               #    0.071 K/sec                  
 6,944,225,684,207      cycles                    #    2.387 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,181,374,489,326      instructions              #    1.90  insns per cycle        
   238,864,300,147      branches                  #   82.105 M/sec                  
     5,305,256,978      branch-misses             #    2.22% of all branches        

    2937.517915589 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.6#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.6#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.7#

               Core t (s)   Wall t (s)        (%)
       Time:     2930.966     2930.966      100.0
                         48:50
                 (ns/day)    (hour/ns)
Performance:        4.422        5.428

GROMACS reminds you: "If Life Seems Jolly Rotten, There's Something You've Forgotten !" (Monty Python)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2903635.387466      task-clock (msec)         #    0.990 CPUs utilized          
           300,694      context-switches          #    0.104 K/sec                  
            15,149      cpu-migrations            #    0.005 K/sec                  
           160,577      page-faults               #    0.055 K/sec                  
 6,910,446,267,054      cycles                    #    2.380 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,002,014,856,172      instructions              #    1.88  insns per cycle        
   233,754,206,071      branches                  #   80.504 M/sec                  
     5,133,317,496      branch-misses             #    2.20% of all branches        

    2931.692837535 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.7#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.7#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.8#

               Core t (s)   Wall t (s)        (%)
       Time:     2925.322     2925.322      100.0
                         48:45
                 (ns/day)    (hour/ns)
Performance:        4.430        5.417

GROMACS reminds you: "Dreams seldom materialize on their own." (Dian Fossey)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2898318.885844      task-clock (msec)         #    0.991 CPUs utilized          
           300,641      context-switches          #    0.104 K/sec                  
            15,140      cpu-migrations            #    0.005 K/sec                  
           216,334      page-faults               #    0.075 K/sec                  
 6,901,639,864,404      cycles                    #    2.381 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,001,358,845,284      instructions              #    1.88  insns per cycle        
   233,794,999,897      branches                  #   80.666 M/sec                  
     5,138,814,984      branch-misses             #    2.20% of all branches        

    2926.074916536 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.8#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.8#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.9#

               Core t (s)   Wall t (s)        (%)
       Time:     2926.288     2926.288      100.0
                         48:46
                 (ns/day)    (hour/ns)
Performance:        4.429        5.419

GROMACS reminds you: "Act like Prometheus would" (Gogol Bordello)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2898949.918263      task-clock (msec)         #    0.990 CPUs utilized          
           300,138      context-switches          #    0.104 K/sec                  
            15,301      cpu-migrations            #    0.005 K/sec                  
           329,664      page-faults               #    0.114 K/sec                  
 6,897,889,531,227      cycles                    #    2.379 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,009,974,889,582      instructions              #    1.89  insns per cycle        
   234,911,598,412      branches                  #   81.033 M/sec                  
     5,333,494,142      branch-misses             #    2.27% of all branches        

    2927.412124459 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.9#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.9#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.10#

               Core t (s)   Wall t (s)        (%)
       Time:     2938.025     2938.025      100.0
                         48:58
                 (ns/day)    (hour/ns)
Performance:        4.411        5.441

GROMACS reminds you: "Shit Happens" (Pulp Fiction)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2910090.427424      task-clock (msec)         #    0.990 CPUs utilized          
           301,330      context-switches          #    0.104 K/sec                  
            15,970      cpu-migrations            #    0.005 K/sec                  
           231,268      page-faults               #    0.079 K/sec                  
 6,916,817,343,241      cycles                    #    2.377 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,011,500,131,917      instructions              #    1.88  insns per cycle        
   234,828,554,486      branches                  #   80.695 M/sec                  
     5,333,226,926      branch-misses             #    2.27% of all branches        

    2938.790413622 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.10#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.10#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.11#

               Core t (s)   Wall t (s)        (%)
       Time:     2936.465     2936.465      100.0
                         48:56
                 (ns/day)    (hour/ns)
Performance:        4.414        5.438

GROMACS reminds you: "Science Won't Change You" (The Talking Heads)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2908482.913020      task-clock (msec)         #    0.990 CPUs utilized          
           301,799      context-switches          #    0.104 K/sec                  
            15,877      cpu-migrations            #    0.005 K/sec                  
           257,736      page-faults               #    0.089 K/sec                  
 6,917,343,621,842      cycles                    #    2.378 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,011,939,487,592      instructions              #    1.88  insns per cycle        
   234,856,556,263      branches                  #   80.749 M/sec                  
     5,323,460,515      branch-misses             #    2.27% of all branches        

    2937.228716992 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.11#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.11#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.12#

               Core t (s)   Wall t (s)        (%)
       Time:     2934.035     2934.035      100.0
                         48:54
                 (ns/day)    (hour/ns)
Performance:        4.417        5.433

GROMACS reminds you: "In science it often happens that scientists say, 'You know that's a really good argument; my position is mistaken,' and then they would actually change their minds and you never hear that old view from them again. They really do it. It doesn't happen as often as it should, because scientists are human and change is sometimes painful. But it happens every day. I cannot recall the last time something like that happened in politics or religion." (Carl Sagan)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2906014.481701      task-clock (msec)         #    0.990 CPUs utilized          
           300,789      context-switches          #    0.104 K/sec                  
            16,143      cpu-migrations            #    0.006 K/sec                  
           198,783      page-faults               #    0.068 K/sec                  
 6,899,109,335,026      cycles                    #    2.374 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
12,991,260,770,617      instructions              #    1.88  insns per cycle        
   232,285,885,934      branches                  #   79.933 M/sec                  
     4,964,882,128      branch-misses             #    2.14% of all branches        

    2934.766825886 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.12#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r412.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.12#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.13#

               Core t (s)   Wall t (s)        (%)
       Time:     2935.442     2935.442      100.0
                         48:55
                 (ns/day)    (hour/ns)
Performance:        4.415        5.436

GROMACS reminds you: "Nobody Never Learnt No-Nothing from No History" (Gogol Bordello)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2907393.052119      task-clock (msec)         #    0.990 CPUs utilized          
           301,165      context-switches          #    0.104 K/sec                  
            15,506      cpu-migrations            #    0.005 K/sec                  
           234,644      page-faults               #    0.081 K/sec                  
 6,917,256,964,322      cycles                    #    2.379 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
12,994,331,789,093      instructions              #    1.88  insns per cycle        
   232,364,700,316      branches                  #   79.922 M/sec                  
     4,960,134,358      branch-misses             #    2.13% of all branches        

    2936.173768538 seconds time elapsed

