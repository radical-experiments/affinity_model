                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.60#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.60#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.60#

               Core t (s)   Wall t (s)        (%)
       Time:     1302.740     1302.740      100.0
                 (ns/day)    (hour/ns)
Performance:        6.632        3.619

GROMACS reminds you: "Can't You Make This Thing Go Faster ?" (Black Crowes)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1303919.870021      task-clock (msec)         #    1.001 CPUs utilized          
             2,006      context-switches          #    0.002 K/sec                  
                31      cpu-migrations            #    0.000 K/sec                  
            49,148      page-faults               #    0.038 K/sec                  
 4,297,609,901,301      cycles                    #    3.296 GHz                    
 9,019,915,681,153      instructions              #    2.10  insn per cycle         
   246,301,534,346      branches                  #  188.893 M/sec                  
     3,092,520,737      branch-misses             #    1.26% of all branches        

    1302.941735092 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.61#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.61#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.61#

               Core t (s)   Wall t (s)        (%)
       Time:     1347.232     1347.232      100.0
                 (ns/day)    (hour/ns)
Performance:        6.413        3.742

GROMACS reminds you: "I know poetry is not dead, nor genius lost; nor has Mammon gained power over either, to bind or slay; they will both assert their existence, their presence, their liberty and strength again one day." (Jane Eyre in Jane Eyre by Charlotte Bronte)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1348453.081091      task-clock (msec)         #    1.001 CPUs utilized          
             2,060      context-switches          #    0.002 K/sec                  
                34      cpu-migrations            #    0.000 K/sec                  
            99,592      page-faults               #    0.074 K/sec                  
 4,444,458,609,019      cycles                    #    3.296 GHz                    
 9,020,420,292,556      instructions              #    2.03  insn per cycle         
   246,343,908,374      branches                  #  182.686 M/sec                  
     3,118,583,129      branch-misses             #    1.27% of all branches        

    1347.438491367 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.62#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.62#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.62#

               Core t (s)   Wall t (s)        (%)
       Time:     1304.805     1304.805      100.0
                 (ns/day)    (hour/ns)
Performance:        6.622        3.624

GROMACS reminds you: "Jesus Built My Hotrod" (Ministry)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1305968.921222      task-clock (msec)         #    1.001 CPUs utilized          
             2,007      context-switches          #    0.002 K/sec                  
                32      cpu-migrations            #    0.000 K/sec                  
            50,999      page-faults               #    0.039 K/sec                  
 4,304,314,535,913      cycles                    #    3.296 GHz                    
 9,020,170,577,754      instructions              #    2.10  insn per cycle         
   246,311,776,262      branches                  #  188.605 M/sec                  
     3,095,387,970      branch-misses             #    1.26% of all branches        

    1305.013919322 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.63#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.63#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.63#

               Core t (s)   Wall t (s)        (%)
       Time:     1331.274     1331.274      100.0
                 (ns/day)    (hour/ns)
Performance:        6.490        3.698

GROMACS reminds you: "There's Still Time to Change the Road You're On" (Led Zeppelin)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1332480.630395      task-clock (msec)         #    1.001 CPUs utilized          
             2,035      context-switches          #    0.002 K/sec                  
                26      cpu-migrations            #    0.000 K/sec                  
            99,829      page-faults               #    0.075 K/sec                  
 4,391,887,145,848      cycles                    #    3.296 GHz                    
 9,019,523,590,393      instructions              #    2.05  insn per cycle         
   246,320,743,557      branches                  #  184.859 M/sec                  
     3,101,067,301      branch-misses             #    1.26% of all branches        

    1331.477181710 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.64#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.64#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.64#

               Core t (s)   Wall t (s)        (%)
       Time:     1302.144     1302.144      100.0
                 (ns/day)    (hour/ns)
Performance:        6.635        3.617

GROMACS reminds you: "It's Time to Move On" (F. Black)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1303289.948690      task-clock (msec)         #    1.001 CPUs utilized          
             2,002      context-switches          #    0.002 K/sec                  
                24      cpu-migrations            #    0.000 K/sec                  
            54,476      page-faults               #    0.042 K/sec                  
 4,296,585,793,909      cycles                    #    3.297 GHz                    
 9,020,627,586,355      instructions              #    2.10  insn per cycle         
   246,316,660,894      branches                  #  188.996 M/sec                  
     3,107,075,901      branch-misses             #    1.26% of all branches        

    1302.313605275 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.65#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.65#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.65#

               Core t (s)   Wall t (s)        (%)
       Time:     1308.807     1308.807      100.0
                 (ns/day)    (hour/ns)
Performance:        6.602        3.636

GROMACS reminds you: "It's Coming Right For Us !" (South Park)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1310000.669550      task-clock (msec)         #    1.001 CPUs utilized          
             2,005      context-switches          #    0.002 K/sec                  
                28      cpu-migrations            #    0.000 K/sec                  
            96,647      page-faults               #    0.074 K/sec                  
 4,317,705,870,457      cycles                    #    3.296 GHz                    
 9,020,351,156,733      instructions              #    2.09  insn per cycle         
   246,315,690,631      branches                  #  188.027 M/sec                  
     3,095,009,510      branch-misses             #    1.26% of all branches        

    1309.009816890 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.66#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.66#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.66#

               Core t (s)   Wall t (s)        (%)
       Time:     1336.802     1336.802      100.0
                 (ns/day)    (hour/ns)
Performance:        6.463        3.713

GROMACS reminds you: "Scientists do not join hands every Sunday and sing "Yes gravity is real! I know gravity is real! I will have faith! I believe in my heart that what goes up, up, up must come down, down, down. Amen!" If they did, we would think they were pretty insecure about the concept." (Dan Barker)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1337996.134657      task-clock (msec)         #    1.001 CPUs utilized          
             2,048      context-switches          #    0.002 K/sec                  
                33      cpu-migrations            #    0.000 K/sec                  
            56,266      page-faults               #    0.042 K/sec                  
 4,409,946,330,456      cycles                    #    3.296 GHz                    
 9,021,479,214,333      instructions              #    2.05  insn per cycle         
   246,331,893,343      branches                  #  184.105 M/sec                  
     3,122,873,655      branch-misses             #    1.27% of all branches        

    1337.000293476 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.67#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.67#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.67#

               Core t (s)   Wall t (s)        (%)
       Time:     1313.231     1313.231      100.0
                 (ns/day)    (hour/ns)
Performance:        6.579        3.648

GROMACS reminds you: "Everything He Lacks, He Makes Up In Denial" (Offspring)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1314425.703559      task-clock (msec)         #    1.001 CPUs utilized          
             2,012      context-switches          #    0.002 K/sec                  
                21      cpu-migrations            #    0.000 K/sec                  
           100,037      page-faults               #    0.076 K/sec                  
 4,332,462,239,486      cycles                    #    3.296 GHz                    
 9,021,974,692,894      instructions              #    2.08  insn per cycle         
   246,328,083,619      branches                  #  187.404 M/sec                  
     3,109,120,031      branch-misses             #    1.26% of all branches        

    1313.435750752 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.68#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.68#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.68#

               Core t (s)   Wall t (s)        (%)
       Time:     1303.197     1303.197      100.0
                 (ns/day)    (hour/ns)
Performance:        6.630        3.620

GROMACS reminds you: "Count the Bubbles In Your Hair" (The Breeders)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1304377.044635      task-clock (msec)         #    1.001 CPUs utilized          
             2,002      context-switches          #    0.002 K/sec                  
                24      cpu-migrations            #    0.000 K/sec                  
            61,474      page-faults               #    0.047 K/sec                  
 4,299,306,494,678      cycles                    #    3.296 GHz                    
 9,021,123,605,807      instructions              #    2.10  insn per cycle         
   246,313,869,692      branches                  #  188.836 M/sec                  
     3,097,315,405      branch-misses             #    1.26% of all branches        

    1303.396437086 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.69#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.69#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.69#

               Core t (s)   Wall t (s)        (%)
       Time:     1341.031     1341.031      100.0
                 (ns/day)    (hour/ns)
Performance:        6.443        3.725

GROMACS reminds you: "Years of calculations and the stress, My science is waiting, nearly complete" (Midlake)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1342244.893099      task-clock (msec)         #    1.001 CPUs utilized          
             2,048      context-switches          #    0.002 K/sec                  
                23      cpu-migrations            #    0.000 K/sec                  
            99,919      page-faults               #    0.074 K/sec                  
 4,424,276,747,384      cycles                    #    3.296 GHz                    
 9,020,969,727,797      instructions              #    2.04  insn per cycle         
   246,332,303,585      branches                  #  183.523 M/sec                  
     3,095,439,422      branch-misses             #    1.26% of all branches        

    1341.231833213 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.70#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.70#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.70#

               Core t (s)   Wall t (s)        (%)
       Time:     1342.859     1342.859      100.0
                 (ns/day)    (hour/ns)
Performance:        6.434        3.730

GROMACS reminds you: "Today we're not going to optimize our CUDA code, cause that's just a rabbit hole of misery!" (Tim Warburton)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1344068.361920      task-clock (msec)         #    1.001 CPUs utilized          
             2,058      context-switches          #    0.002 K/sec                  
                25      cpu-migrations            #    0.000 K/sec                  
            65,673      page-faults               #    0.049 K/sec                  
 4,430,446,253,288      cycles                    #    3.296 GHz                    
 9,021,055,148,821      instructions              #    2.04  insn per cycle         
   246,343,362,915      branches                  #  183.282 M/sec                  
     3,124,941,825      branch-misses             #    1.27% of all branches        

    1343.059576502 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.71#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.71#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.71#

               Core t (s)   Wall t (s)        (%)
       Time:     1308.176     1308.176      100.0
                 (ns/day)    (hour/ns)
Performance:        6.605        3.634

GROMACS reminds you: "Carry Me Away" (Motors)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1309373.176104      task-clock (msec)         #    1.001 CPUs utilized          
             2,006      context-switches          #    0.002 K/sec                  
                28      cpu-migrations            #    0.000 K/sec                  
            96,641      page-faults               #    0.074 K/sec                  
 4,315,962,770,707      cycles                    #    3.296 GHz                    
 9,020,181,309,807      instructions              #    2.09  insn per cycle         
   246,311,003,523      branches                  #  188.114 M/sec                  
     3,120,215,215      branch-misses             #    1.27% of all branches        

    1308.384119520 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.72#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.72#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.72#

               Core t (s)   Wall t (s)        (%)
       Time:     1306.658     1306.658      100.0
                 (ns/day)    (hour/ns)
Performance:        6.612        3.630

GROMACS reminds you: "No great discovery was ever made without a bold guess." (Marie Curie)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1307844.761570      task-clock (msec)         #    1.001 CPUs utilized          
             2,004      context-switches          #    0.002 K/sec                  
                29      cpu-migrations            #    0.000 K/sec                  
            67,931      page-faults               #    0.052 K/sec                  
 4,307,650,827,694      cycles                    #    3.294 GHz                    
 9,021,978,096,643      instructions              #    2.09  insn per cycle         
   246,338,293,233      branches                  #  188.354 M/sec                  
     3,131,515,780      branch-misses             #    1.27% of all branches        

    1306.860486962 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.73#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.73#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.73#

               Core t (s)   Wall t (s)        (%)
       Time:     1316.052     1316.052      100.0
                 (ns/day)    (hour/ns)
Performance:        6.565        3.656

GROMACS reminds you: "Live for Liposuction" (Robbie Williams)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1317246.895684      task-clock (msec)         #    1.001 CPUs utilized          
             2,014      context-switches          #    0.002 K/sec                  
                25      cpu-migrations            #    0.000 K/sec                  
            99,934      page-faults               #    0.076 K/sec                  
 4,342,419,170,319      cycles                    #    3.297 GHz                    
 9,021,136,322,701      instructions              #    2.08  insn per cycle         
   246,329,102,867      branches                  #  187.003 M/sec                  
     3,121,516,914      branch-misses             #    1.27% of all branches        

    1316.250285180 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_8
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.74#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0045.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.74#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.74#

               Core t (s)   Wall t (s)        (%)
       Time:     1306.214     1306.214      100.0
                 (ns/day)    (hour/ns)
Performance:        6.615        3.628

GROMACS reminds you: "She's a Good Sheila Bruce" (Monty Python)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1307403.600177      task-clock (msec)         #    1.001 CPUs utilized          
             2,006      context-switches          #    0.002 K/sec                  
                25      cpu-migrations            #    0.000 K/sec                  
            71,049      page-faults               #    0.054 K/sec                  
 4,308,989,371,014      cycles                    #    3.296 GHz                    
 9,019,275,099,101      instructions              #    2.09  insn per cycle         
   246,295,044,217      branches                  #  188.385 M/sec                  
     3,119,720,102      branch-misses             #    1.27% of all branches        

    1306.422725200 seconds time elapsed

