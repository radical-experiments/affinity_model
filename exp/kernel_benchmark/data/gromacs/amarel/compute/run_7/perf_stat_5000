                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.15#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.15#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.15#

               Core t (s)   Wall t (s)        (%)
       Time:      169.366      169.366      100.0
                 (ns/day)    (hour/ns)
Performance:        5.102        4.704

GROMACS reminds you: "The lovliest theories are being overthrown by these damned experiments; it is no fun being a chemist any more." (Justus von Liebig, letter to J.J. Berzelius 1834)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     169428.931485      task-clock (msec)         #    0.999 CPUs utilized          
            17,660      context-switches          #    0.104 K/sec                  
                 8      cpu-migrations            #    0.000 K/sec                  
            40,120      page-faults               #    0.237 K/sec                  
   557,312,403,804      cycles                    #    3.289 GHz                    
   297,745,670,605      stalled-cycles-frontend   #   53.43% frontend cycles idle   
    54,757,156,236      stalled-cycles-backend    #    9.83% backend cycles idle    
   915,911,518,409      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
    25,087,013,868      branches                  #  148.068 M/sec                  
       371,362,597      branch-misses             #    1.48% of all branches        

     169.514008513 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.16#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.16#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.16#

               Core t (s)   Wall t (s)        (%)
       Time:      168.829      168.829      100.0
                 (ns/day)    (hour/ns)
Performance:        5.119        4.689

GROMACS reminds you: "I do not believe continuum electrostatics" (Arieh Warshel, Nobel lecture 2013)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     168893.533827      task-clock (msec)         #    1.000 CPUs utilized          
            17,608      context-switches          #    0.104 K/sec                  
                 7      cpu-migrations            #    0.000 K/sec                  
            39,617      page-faults               #    0.235 K/sec                  
   555,587,224,509      cycles                    #    3.290 GHz                    
   296,004,140,238      stalled-cycles-frontend   #   53.28% frontend cycles idle   
    52,834,490,472      stalled-cycles-backend    #    9.51% backend cycles idle    
   915,974,359,932      instructions              #    1.65  insn per cycle         
                                                  #    0.32  stalled cycles per insn
    25,087,979,240      branches                  #  148.543 M/sec                  
       371,626,008      branch-misses             #    1.48% of all branches        

     168.977112835 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.17#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.17#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.17#

               Core t (s)   Wall t (s)        (%)
       Time:      168.604      168.604      100.0
                 (ns/day)    (hour/ns)
Performance:        5.125        4.682

GROMACS reminds you: "A ship in port is safe, but that is not what ships are for. Sail out to sea and do new things." (Grace Hopper, developer of COBOL)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     168672.991284      task-clock (msec)         #    1.000 CPUs utilized          
            17,604      context-switches          #    0.104 K/sec                  
                13      cpu-migrations            #    0.000 K/sec                  
            40,012      page-faults               #    0.237 K/sec                  
   554,839,548,845      cycles                    #    3.289 GHz                    
   295,333,178,832      stalled-cycles-frontend   #   53.23% frontend cycles idle   
    52,630,984,489      stalled-cycles-backend    #    9.49% backend cycles idle    
   915,685,478,386      instructions              #    1.65  insn per cycle         
                                                  #    0.32  stalled cycles per insn
    25,086,823,551      branches                  #  148.731 M/sec                  
       370,966,718      branch-misses             #    1.48% of all branches        

     168.753393346 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.18#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.18#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.18#

               Core t (s)   Wall t (s)        (%)
       Time:      168.348      168.348      100.0
                 (ns/day)    (hour/ns)
Performance:        5.133        4.675

GROMACS reminds you: "I think everybody should like everybody." (Andy Warhol)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     168424.811806      task-clock (msec)         #    1.000 CPUs utilized          
            17,567      context-switches          #    0.104 K/sec                  
                10      cpu-migrations            #    0.000 K/sec                  
            40,129      page-faults               #    0.238 K/sec                  
   554,041,728,276      cycles                    #    3.290 GHz                    
   294,650,898,487      stalled-cycles-frontend   #   53.18% frontend cycles idle   
    52,197,808,169      stalled-cycles-backend    #    9.42% backend cycles idle    
   915,288,791,960      instructions              #    1.65  insn per cycle         
                                                  #    0.32  stalled cycles per insn
    25,079,783,247      branches                  #  148.908 M/sec                  
       370,608,004      branch-misses             #    1.48% of all branches        

     168.502801398 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.19#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.19#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.19#

               Core t (s)   Wall t (s)        (%)
       Time:      168.486      168.486      100.0
                 (ns/day)    (hour/ns)
Performance:        5.129        4.679

GROMACS reminds you: "If it's a good idea, go ahead and do it. It's much easier to apologize than it is to get permission." (Grace Hopper, developer of COBOL)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     168556.464535      task-clock (msec)         #    1.000 CPUs utilized          
            17,572      context-switches          #    0.104 K/sec                  
                10      cpu-migrations            #    0.000 K/sec                  
            40,078      page-faults               #    0.238 K/sec                  
   554,445,324,753      cycles                    #    3.289 GHz                    
   294,902,046,207      stalled-cycles-frontend   #   53.19% frontend cycles idle   
    52,328,148,875      stalled-cycles-backend    #    9.44% backend cycles idle    
   915,833,443,781      instructions              #    1.65  insn per cycle         
                                                  #    0.32  stalled cycles per insn
    25,087,243,072      branches                  #  148.836 M/sec                  
       369,636,014      branch-misses             #    1.47% of all branches        

     168.634535449 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.20#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.20#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.20#

               Core t (s)   Wall t (s)        (%)
       Time:      197.465      197.465      100.0
                 (ns/day)    (hour/ns)
Performance:        4.376        5.484

GROMACS reminds you: "During my undergraduate work I concluded that electrostatics is unlikely to be important [for enzymes]" (Arieh Warshel, Nobel lecture 2013)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     197525.162445      task-clock (msec)         #    1.000 CPUs utilized          
            20,526      context-switches          #    0.104 K/sec                  
                 5      cpu-migrations            #    0.000 K/sec                  
            42,891      page-faults               #    0.217 K/sec                  
   649,777,611,161      cycles                    #    3.290 GHz                    
   390,420,245,121      stalled-cycles-frontend   #   60.09% frontend cycles idle   
   103,759,343,640      stalled-cycles-backend    #   15.97% backend cycles idle    
   915,985,274,977      instructions              #    1.41  insn per cycle         
                                                  #    0.43  stalled cycles per insn
    25,104,133,037      branches                  #  127.093 M/sec                  
       371,146,050      branch-misses             #    1.48% of all branches        

     197.609791501 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.21#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.21#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.21#

               Core t (s)   Wall t (s)        (%)
       Time:      168.915      168.915      100.0
                 (ns/day)    (hour/ns)
Performance:        5.116        4.691

GROMACS reminds you: "I believe in miracles cause I'm one" (The Ramones)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     168972.695926      task-clock (msec)         #    0.999 CPUs utilized          
            17,643      context-switches          #    0.104 K/sec                  
                10      cpu-migrations            #    0.000 K/sec                  
            40,010      page-faults               #    0.237 K/sec                  
   555,818,088,803      cycles                    #    3.289 GHz                    
   296,231,499,821      stalled-cycles-frontend   #   53.30% frontend cycles idle   
    52,713,650,985      stalled-cycles-backend    #    9.48% backend cycles idle    
   916,143,314,048      instructions              #    1.65  insn per cycle         
                                                  #    0.32  stalled cycles per insn
    25,087,621,942      branches                  #  148.471 M/sec                  
       372,935,440      branch-misses             #    1.49% of all branches        

     169.061463901 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.22#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.22#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.22#

               Core t (s)   Wall t (s)        (%)
       Time:      169.205      169.205      100.0
                 (ns/day)    (hour/ns)
Performance:        5.107        4.699

GROMACS reminds you: "This May Come As a Shock" (F. Black)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     169276.916982      task-clock (msec)         #    1.000 CPUs utilized          
            17,649      context-switches          #    0.104 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            39,604      page-faults               #    0.234 K/sec                  
   556,815,863,268      cycles                    #    3.289 GHz                    
   297,356,223,650      stalled-cycles-frontend   #   53.40% frontend cycles idle   
    53,723,473,271      stalled-cycles-backend    #    9.65% backend cycles idle    
   915,739,311,072      instructions              #    1.64  insn per cycle         
                                                  #    0.32  stalled cycles per insn
    25,086,086,730      branches                  #  148.196 M/sec                  
       371,466,136      branch-misses             #    1.48% of all branches        

     169.353764581 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.23#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.23#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.23#

               Core t (s)   Wall t (s)        (%)
       Time:      197.337      197.337      100.0
                 (ns/day)    (hour/ns)
Performance:        4.379        5.480

GROMACS reminds you: "I'd be Safe and Warm if I was in L.A." (The Mamas and the Papas)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     197400.015346      task-clock (msec)         #    1.000 CPUs utilized          
            20,511      context-switches          #    0.104 K/sec                  
                 7      cpu-migrations            #    0.000 K/sec                  
            42,527      page-faults               #    0.215 K/sec                  
   649,350,081,232      cycles                    #    3.290 GHz                    
   390,071,512,828      stalled-cycles-frontend   #   60.07% frontend cycles idle   
   103,488,510,639      stalled-cycles-backend    #   15.94% backend cycles idle    
   915,797,032,003      instructions              #    1.41  insn per cycle         
                                                  #    0.43  stalled cycles per insn
    25,102,791,418      branches                  #  127.167 M/sec                  
       369,462,883      branch-misses             #    1.47% of all branches        

     197.483152381 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.24#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.24#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.24#

               Core t (s)   Wall t (s)        (%)
       Time:      168.436      168.436      100.0
                 (ns/day)    (hour/ns)
Performance:        5.131        4.678

GROMACS reminds you: "Science is the great antidote to the poison of enthusiasm and superstition." (Adam Smith, Wealth of Nations, 1776)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     168494.920995      task-clock (msec)         #    0.999 CPUs utilized          
            17,571      context-switches          #    0.104 K/sec                  
                10      cpu-migrations            #    0.000 K/sec                  
            39,332      page-faults               #    0.233 K/sec                  
   554,241,541,648      cycles                    #    3.289 GHz                    
   294,702,418,082      stalled-cycles-frontend   #   53.17% frontend cycles idle   
    51,851,511,017      stalled-cycles-backend    #    9.36% backend cycles idle    
   915,982,119,794      instructions              #    1.65  insn per cycle         
                                                  #    0.32  stalled cycles per insn
    25,087,934,697      branches                  #  148.894 M/sec                  
       372,678,103      branch-misses             #    1.49% of all branches        

     168.581323240 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.25#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.25#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.25#

               Core t (s)   Wall t (s)        (%)
       Time:      197.389      197.389      100.0
                 (ns/day)    (hour/ns)
Performance:        4.378        5.482

GROMACS reminds you: "Everybody's Good Enough For Some Change" (LIVE)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     197446.126900      task-clock (msec)         #    1.000 CPUs utilized          
            20,531      context-switches          #    0.104 K/sec                  
                 9      cpu-migrations            #    0.000 K/sec                  
            42,914      page-faults               #    0.217 K/sec                  
   649,467,643,851      cycles                    #    3.289 GHz                    
   390,074,783,336      stalled-cycles-frontend   #   60.06% frontend cycles idle   
   103,289,781,790      stalled-cycles-backend    #   15.90% backend cycles idle    
   916,176,853,761      instructions              #    1.41  insn per cycle         
                                                  #    0.43  stalled cycles per insn
    25,109,635,200      branches                  #  127.172 M/sec                  
       371,529,873      branch-misses             #    1.48% of all branches        

     197.536877454 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.26#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.26#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.26#

               Core t (s)   Wall t (s)        (%)
       Time:      168.581      168.581      100.0
                 (ns/day)    (hour/ns)
Performance:        5.126        4.682

GROMACS reminds you: "Torture numbers, and they'll confess to anything." (Greg Easterbrook)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     168643.893784      task-clock (msec)         #    1.000 CPUs utilized          
            17,582      context-switches          #    0.104 K/sec                  
                 7      cpu-migrations            #    0.000 K/sec                  
            39,955      page-faults               #    0.237 K/sec                  
   554,655,755,955      cycles                    #    3.289 GHz                    
   295,174,435,212      stalled-cycles-frontend   #   53.22% frontend cycles idle   
    52,595,200,413      stalled-cycles-backend    #    9.48% backend cycles idle    
   915,641,274,152      instructions              #    1.65  insn per cycle         
                                                  #    0.32  stalled cycles per insn
    25,084,091,966      branches                  #  148.740 M/sec                  
       370,423,764      branch-misses             #    1.48% of all branches        

     168.725919756 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.27#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.27#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.27#

               Core t (s)   Wall t (s)        (%)
       Time:      169.357      169.357      100.0
                 (ns/day)    (hour/ns)
Performance:        5.103        4.703

GROMACS reminds you: "Here, kitty, kitty..." (Erwin Schroedinger)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     169423.490123      task-clock (msec)         #    1.000 CPUs utilized          
            17,666      context-switches          #    0.104 K/sec                  
                13      cpu-migrations            #    0.000 K/sec                  
            39,947      page-faults               #    0.236 K/sec                  
   557,248,185,997      cycles                    #    3.289 GHz                    
   297,767,484,843      stalled-cycles-frontend   #   53.44% frontend cycles idle   
    54,938,994,324      stalled-cycles-backend    #    9.86% backend cycles idle    
   915,708,075,820      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
    25,084,883,607      branches                  #  148.060 M/sec                  
       369,835,807      branch-misses             #    1.47% of all branches        

     169.505643681 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.28#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.28#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.28#

               Core t (s)   Wall t (s)        (%)
       Time:      168.581      168.581      100.0
                 (ns/day)    (hour/ns)
Performance:        5.126        4.682

GROMACS reminds you: "With a Lead Filled Snowshoe" (F. Zappa)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     168647.606107      task-clock (msec)         #    1.000 CPUs utilized          
            17,582      context-switches          #    0.104 K/sec                  
                 5      cpu-migrations            #    0.000 K/sec                  
            39,608      page-faults               #    0.235 K/sec                  
   554,745,584,029      cycles                    #    3.289 GHz                    
   295,232,708,051      stalled-cycles-frontend   #   53.22% frontend cycles idle   
    52,214,046,766      stalled-cycles-backend    #    9.41% backend cycles idle    
   915,974,051,262      instructions              #    1.65  insn per cycle         
                                                  #    0.32  stalled cycles per insn
    25,085,944,046      branches                  #  148.748 M/sec                  
       372,369,372      branch-misses             #    1.48% of all branches        

     168.727221698 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.29#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.29#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.29#

               Core t (s)   Wall t (s)        (%)
       Time:      168.467      168.467      100.0
                 (ns/day)    (hour/ns)
Performance:        5.130        4.679

GROMACS reminds you: "Dreams seldom materialize on their own." (Dian Fossey)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     168529.571655      task-clock (msec)         #    1.000 CPUs utilized          
            17,565      context-switches          #    0.104 K/sec                  
                 8      cpu-migrations            #    0.000 K/sec                  
            39,609      page-faults               #    0.235 K/sec                  
   554,355,311,974      cycles                    #    3.289 GHz                    
   294,817,184,322      stalled-cycles-frontend   #   53.18% frontend cycles idle   
    52,099,026,496      stalled-cycles-backend    #    9.40% backend cycles idle    
   915,985,415,394      instructions              #    1.65  insn per cycle         
                                                  #    0.32  stalled cycles per insn
    25,088,097,322      branches                  #  148.865 M/sec                  
       370,060,944      branch-misses             #    1.48% of all branches        

     168.613385899 seconds time elapsed

