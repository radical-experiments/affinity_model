                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.15#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.15#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.15#

               Core t (s)   Wall t (s)        (%)
       Time:      152.698      152.698      100.0
                 (ns/day)    (hour/ns)
Performance:        5.659        4.241

GROMACS reminds you: "You're like them scientists on TV explaining black holes. More you talk, less I get" (Jess Walter)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152832.675543      task-clock (msec)         #    0.999 CPUs utilized          
               559      context-switches          #    0.004 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            44,651      page-faults               #    0.292 K/sec                  
   426,658,616,339      cycles                    #    2.792 GHz                    
   902,931,660,849      instructions              #    2.12  insn per cycle         
    24,776,080,249      branches                  #  162.112 M/sec                  
       314,361,738      branch-misses             #    1.27% of all branches        

     152.944079430 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.16#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.16#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.16#

               Core t (s)   Wall t (s)        (%)
       Time:      152.732      152.732      100.0
                 (ns/day)    (hour/ns)
Performance:        5.658        4.242

GROMACS reminds you: "Lunatics On Pogo Sticks" (Red Hot Chili Peppers)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152888.622131      task-clock (msec)         #    0.999 CPUs utilized          
               561      context-switches          #    0.004 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            44,727      page-faults               #    0.293 K/sec                  
   426,784,256,869      cycles                    #    2.791 GHz                    
   902,799,236,041      instructions              #    2.12  insn per cycle         
    24,774,913,484      branches                  #  162.046 M/sec                  
       312,697,683      branch-misses             #    1.26% of all branches        

     153.017755353 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.17#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.17#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.17#

               Core t (s)   Wall t (s)        (%)
       Time:      152.099      152.099      100.0
                 (ns/day)    (hour/ns)
Performance:        5.682        4.224

GROMACS reminds you: "The Universe is Somewhere In Here" (J.G.E.M. Fraaije)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152226.165285      task-clock (msec)         #    0.999 CPUs utilized          
               560      context-switches          #    0.004 K/sec                  
                 8      cpu-migrations            #    0.000 K/sec                  
            23,063      page-faults               #    0.152 K/sec                  
   425,045,092,945      cycles                    #    2.792 GHz                    
   902,850,458,134      instructions              #    2.12  insn per cycle         
    24,773,957,202      branches                  #  162.744 M/sec                  
       313,394,454      branch-misses             #    1.27% of all branches        

     152.346935914 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.18#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.18#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.18#

               Core t (s)   Wall t (s)        (%)
       Time:      152.697      152.697      100.0
                 (ns/day)    (hour/ns)
Performance:        5.659        4.241

GROMACS reminds you: "Don't Push Me, Cause I'm Close to the Edge" (Tricky)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152839.648499      task-clock (msec)         #    0.999 CPUs utilized          
               555      context-switches          #    0.004 K/sec                  
                 7      cpu-migrations            #    0.000 K/sec                  
            44,889      page-faults               #    0.294 K/sec                  
   426,741,922,961      cycles                    #    2.792 GHz                    
   902,706,351,074      instructions              #    2.12  insn per cycle         
    24,774,997,319      branches                  #  162.098 M/sec                  
       312,362,184      branch-misses             #    1.26% of all branches        

     152.952778853 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.19#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.19#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.19#

               Core t (s)   Wall t (s)        (%)
       Time:      152.679      152.679      100.0
                 (ns/day)    (hour/ns)
Performance:        5.660        4.240

GROMACS reminds you: "One Cross Each" (Monty Python)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152875.227647      task-clock (msec)         #    0.999 CPUs utilized          
               555      context-switches          #    0.004 K/sec                  
                 4      cpu-migrations            #    0.000 K/sec                  
            44,874      page-faults               #    0.294 K/sec                  
   426,633,982,636      cycles                    #    2.791 GHz                    
   902,230,552,208      instructions              #    2.11  insn per cycle         
    24,771,716,091      branches                  #  162.039 M/sec                  
       313,737,527      branch-misses             #    1.27% of all branches        

     152.988354669 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.20#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.20#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.20#

               Core t (s)   Wall t (s)        (%)
       Time:      152.599      152.599      100.0
                 (ns/day)    (hour/ns)
Performance:        5.663        4.238

GROMACS reminds you: "Disturb the Peace of a John Q Citizen" (Urban Dance Squad)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152757.939927      task-clock (msec)         #    0.999 CPUs utilized          
               559      context-switches          #    0.004 K/sec                  
                 4      cpu-migrations            #    0.000 K/sec                  
            44,378      page-faults               #    0.291 K/sec                  
   426,482,251,491      cycles                    #    2.792 GHz                    
   902,453,013,943      instructions              #    2.12  insn per cycle         
    24,773,065,903      branches                  #  162.172 M/sec                  
       311,680,892      branch-misses             #    1.26% of all branches        

     152.870456016 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.21#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.21#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.21#

               Core t (s)   Wall t (s)        (%)
       Time:      152.782      152.782      100.0
                 (ns/day)    (hour/ns)
Performance:        5.656        4.243

GROMACS reminds you: "They don't have half hours in the north" (Carl Caleman)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152926.362458      task-clock (msec)         #    0.999 CPUs utilized          
               556      context-switches          #    0.004 K/sec                  
                 7      cpu-migrations            #    0.000 K/sec                  
            44,381      page-faults               #    0.290 K/sec                  
   427,026,189,845      cycles                    #    2.792 GHz                    
   903,001,713,710      instructions              #    2.11  insn per cycle         
    24,776,143,184      branches                  #  162.014 M/sec                  
       312,429,789      branch-misses             #    1.26% of all branches        

     153.040930032 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.22#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.22#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.22#

               Core t (s)   Wall t (s)        (%)
       Time:      153.581      153.581      100.0
                 (ns/day)    (hour/ns)
Performance:        5.627        4.265

GROMACS reminds you: "Isnâ€™t this enough? Just this world? Just this beautiful, complex wonderfully unfathomable world? How does it so fail to hold our attention that we have to diminish it with the invention of cheap, man-made myths and monsters?" (Tim Minchin)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     153669.298358      task-clock (msec)         #    0.999 CPUs utilized          
               560      context-switches          #    0.004 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            44,479      page-faults               #    0.289 K/sec                  
   429,229,412,082      cycles                    #    2.793 GHz                    
   902,446,290,316      instructions              #    2.10  insn per cycle         
    24,773,329,828      branches                  #  161.212 M/sec                  
       312,676,139      branch-misses             #    1.26% of all branches        

     153.783442809 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.23#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.23#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.23#

               Core t (s)   Wall t (s)        (%)
       Time:      152.670      152.670      100.0
                 (ns/day)    (hour/ns)
Performance:        5.660        4.240

GROMACS reminds you: "We Look Pretty Sharp In These Clothes" (F. Zappa)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152765.068917      task-clock (msec)         #    0.999 CPUs utilized          
               551      context-switches          #    0.004 K/sec                  
                 5      cpu-migrations            #    0.000 K/sec                  
            44,529      page-faults               #    0.291 K/sec                  
   426,717,507,694      cycles                    #    2.793 GHz                    
   902,947,995,049      instructions              #    2.12  insn per cycle         
    24,778,034,674      branches                  #  162.197 M/sec                  
       315,158,100      branch-misses             #    1.27% of all branches        

     152.878558763 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.24#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.24#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.24#

               Core t (s)   Wall t (s)        (%)
       Time:      152.675      152.675      100.0
                 (ns/day)    (hour/ns)
Performance:        5.660        4.240

GROMACS reminds you: "According to my computations we're overdue for a transformation." (Jackson Browne)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152818.233259      task-clock (msec)         #    0.999 CPUs utilized          
               565      context-switches          #    0.004 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            44,890      page-faults               #    0.294 K/sec                  
   426,743,739,130      cycles                    #    2.792 GHz                    
   902,664,491,673      instructions              #    2.12  insn per cycle         
    24,775,707,259      branches                  #  162.125 M/sec                  
       313,223,038      branch-misses             #    1.26% of all branches        

     152.929026212 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.25#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.25#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.25#

               Core t (s)   Wall t (s)        (%)
       Time:      155.413      155.413      100.0
                 (ns/day)    (hour/ns)
Performance:        5.560        4.316

GROMACS reminds you: "Garbage Collecting..." (GNU Emacs)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     155608.422074      task-clock (msec)         #    0.999 CPUs utilized          
               563      context-switches          #    0.004 K/sec                  
                 5      cpu-migrations            #    0.000 K/sec                  
            44,387      page-faults               #    0.285 K/sec                  
   434,366,587,858      cycles                    #    2.791 GHz                    
   902,794,264,900      instructions              #    2.08  insn per cycle         
    24,776,367,418      branches                  #  159.223 M/sec                  
       312,904,470      branch-misses             #    1.26% of all branches        

     155.720736853 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.26#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.26#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.26#

               Core t (s)   Wall t (s)        (%)
       Time:      152.736      152.736      100.0
                 (ns/day)    (hour/ns)
Performance:        5.658        4.242

GROMACS reminds you: "The Poodle Bites" (F. Zappa)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152866.391540      task-clock (msec)         #    0.999 CPUs utilized          
               557      context-switches          #    0.004 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            44,832      page-faults               #    0.293 K/sec                  
   426,824,690,585      cycles                    #    2.792 GHz                    
   902,500,624,961      instructions              #    2.11  insn per cycle         
    24,773,174,856      branches                  #  162.058 M/sec                  
       313,158,654      branch-misses             #    1.26% of all branches        

     152.991363458 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.27#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.27#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.27#

               Core t (s)   Wall t (s)        (%)
       Time:      152.773      152.773      100.0
                 (ns/day)    (hour/ns)
Performance:        5.657        4.243

GROMACS reminds you: "Heard a talk introducing a new language called Swift, from a guy named Wozniak, and it had nothing to do with Apple!" (Adam Cadien)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152908.332126      task-clock (msec)         #    0.999 CPUs utilized          
               559      context-switches          #    0.004 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            44,401      page-faults               #    0.290 K/sec                  
   426,971,535,089      cycles                    #    2.792 GHz                    
   902,981,220,874      instructions              #    2.11  insn per cycle         
    24,779,082,134      branches                  #  162.052 M/sec                  
       312,558,397      branch-misses             #    1.26% of all branches        

     153.021391133 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.28#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.28#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.28#

               Core t (s)   Wall t (s)        (%)
       Time:      152.581      152.581      100.0
                 (ns/day)    (hour/ns)
Performance:        5.664        4.238

GROMACS reminds you: "If You Want Something Done You Have to Do It Yourself" (Highlander II)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     152772.952471      task-clock (msec)         #    0.999 CPUs utilized          
               559      context-switches          #    0.004 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            44,740      page-faults               #    0.293 K/sec                  
   426,476,996,566      cycles                    #    2.792 GHz                    
   902,642,462,153      instructions              #    2.12  insn per cycle         
    24,773,968,180      branches                  #  162.162 M/sec                  
       311,365,287      branch-misses             #    1.26% of all branches        

     152.886995369 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/mem/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.29#

Running on 1 node with total 56 cores, 56 logical cores
Hardware detected on host mem002.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E7-4830 v4 @ 2.00GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.29#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.29#

               Core t (s)   Wall t (s)        (%)
       Time:      156.424      156.424      100.0
                 (ns/day)    (hour/ns)
Performance:        5.525        4.344

GROMACS reminds you: "You Crashed Into the Swamps" (Silicon Graphics)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     156608.626876      task-clock (msec)         #    0.999 CPUs utilized          
               564      context-switches          #    0.004 K/sec                  
                 4      cpu-migrations            #    0.000 K/sec                  
            44,389      page-faults               #    0.283 K/sec                  
   437,198,244,787      cycles                    #    2.792 GHz                    
   903,039,899,257      instructions              #    2.07  insn per cycle         
    24,778,816,661      branches                  #  158.221 M/sec                  
       314,781,492      branch-misses             #    1.27% of all branches        

     156.724811681 seconds time elapsed

