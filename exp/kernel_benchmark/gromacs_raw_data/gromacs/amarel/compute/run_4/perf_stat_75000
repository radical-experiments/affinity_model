                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.75#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.75#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.75#

               Core t (s)   Wall t (s)        (%)
       Time:     1966.910     1966.910      100.0
                         32:46
                 (ns/day)    (hour/ns)
Performance:        6.589        3.642

GROMACS reminds you: "If There Is No Guitar In The House, You Know It's Owner Can Not Be Trusted" (Gogol Bordello)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1968608.419418      task-clock (msec)         #    1.001 CPUs utilized          
             2,926      context-switches          #    0.001 K/sec                  
                49      cpu-migrations            #    0.000 K/sec                  
           114,653      page-faults               #    0.058 K/sec                  
 6,489,239,073,736      cycles                    #    3.296 GHz                    
13,529,246,067,964      instructions              #    2.08  insn per cycle         
   369,416,433,400      branches                  #  187.654 M/sec                  
     4,662,445,807      branch-misses             #    1.26% of all branches        

    1967.110999193 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.76#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.76#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.76#

               Core t (s)   Wall t (s)        (%)
       Time:     1967.791     1967.791      100.0
                         32:47
                 (ns/day)    (hour/ns)
Performance:        6.586        3.644

GROMACS reminds you: "Creativity in science, as in art, cannot be organized. It arises spontaneously from individual talent. Well-run laboratories can foster it, but hierarchical organizations, inflexible bureaucratic rules, and mountains of futile paperwork can kill it." (Max Perutz)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1969494.760449      task-clock (msec)         #    1.001 CPUs utilized          
             2,929      context-switches          #    0.001 K/sec                  
                42      cpu-migrations            #    0.000 K/sec                  
           129,939      page-faults               #    0.066 K/sec                  
 6,492,298,048,540      cycles                    #    3.296 GHz                    
13,529,469,418,781      instructions              #    2.08  insn per cycle         
   369,408,599,629      branches                  #  187.565 M/sec                  
     4,667,397,825      branch-misses             #    1.26% of all branches        

    1967.992077710 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.77#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.77#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.77#

               Core t (s)   Wall t (s)        (%)
       Time:     1958.046     1958.046      100.0
                         32:38
                 (ns/day)    (hour/ns)
Performance:        6.619        3.626

GROMACS reminds you: "Once Again Let Me Do This" (Urban Dance Squad)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1959737.889045      task-clock (msec)         #    1.001 CPUs utilized          
             2,918      context-switches          #    0.001 K/sec                  
                44      cpu-migrations            #    0.000 K/sec                  
            53,715      page-faults               #    0.027 K/sec                  
 6,460,191,491,522      cycles                    #    3.296 GHz                    
13,528,978,617,766      instructions              #    2.09  insn per cycle         
   369,383,568,560      branches                  #  188.486 M/sec                  
     4,661,913,180      branch-misses             #    1.26% of all branches        

    1958.243526253 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.78#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.78#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.78#

               Core t (s)   Wall t (s)        (%)
       Time:     1961.196     1961.196      100.0
                         32:41
                 (ns/day)    (hour/ns)
Performance:        6.608        3.632

GROMACS reminds you: "Never, I said never, compare with experiment" (Magnus Bergh)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1962878.769656      task-clock (msec)         #    1.001 CPUs utilized          
             2,920      context-switches          #    0.001 K/sec                  
                51      cpu-migrations            #    0.000 K/sec                  
            86,066      page-faults               #    0.044 K/sec                  
 6,470,490,480,222      cycles                    #    3.296 GHz                    
13,532,478,316,531      instructions              #    2.09  insn per cycle         
   369,433,964,117      branches                  #  188.210 M/sec                  
     4,642,922,164      branch-misses             #    1.26% of all branches        

    1961.382499253 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.79#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.79#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.79#

               Core t (s)   Wall t (s)        (%)
       Time:     1964.865     1964.865      100.0
                         32:44
                 (ns/day)    (hour/ns)
Performance:        6.596        3.639

GROMACS reminds you: "Theoretical chemistry has of course always been important and useful ... at least to theoretical chemists" (Sven Lidin)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1966547.577137      task-clock (msec)         #    1.001 CPUs utilized          
             2,924      context-switches          #    0.001 K/sec                  
                49      cpu-migrations            #    0.000 K/sec                  
           120,399      page-faults               #    0.061 K/sec                  
 6,482,688,916,398      cycles                    #    3.296 GHz                    
13,531,445,334,030      instructions              #    2.09  insn per cycle         
   369,446,536,136      branches                  #  187.866 M/sec                  
     4,644,107,167      branch-misses             #    1.26% of all branches        

    1965.051441370 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.80#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.80#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.80#

               Core t (s)   Wall t (s)        (%)
       Time:     2001.117     2001.117      100.0
                         33:21
                 (ns/day)    (hour/ns)
Performance:        6.476        3.706

GROMACS reminds you: "Screw a Lightbulb in your Head" (Gogol Bordello)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2002848.520492      task-clock (msec)         #    1.001 CPUs utilized          
             2,969      context-switches          #    0.001 K/sec                  
                48      cpu-migrations            #    0.000 K/sec                  
           132,842      page-faults               #    0.066 K/sec                  
 6,602,260,692,882      cycles                    #    3.296 GHz                    
13,526,873,838,778      instructions              #    2.05  insn per cycle         
   369,406,666,524      branches                  #  184.441 M/sec                  
     4,677,653,955      branch-misses             #    1.27% of all branches        

    2001.315977080 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.81#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.81#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.81#

               Core t (s)   Wall t (s)        (%)
       Time:     1959.699     1959.699      100.0
                         32:39
                 (ns/day)    (hour/ns)
Performance:        6.613        3.629

GROMACS reminds you: "UNIX is basically a simple operating system. It just takes a genius to understand its simplicity." (Dennis Ritchie)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1961398.542474      task-clock (msec)         #    1.001 CPUs utilized          
             2,919      context-switches          #    0.001 K/sec                  
                46      cpu-migrations            #    0.000 K/sec                  
            62,129      page-faults               #    0.032 K/sec                  
 6,465,885,653,718      cycles                    #    3.297 GHz                    
13,531,057,994,520      instructions              #    2.09  insn per cycle         
   369,415,196,823      branches                  #  188.343 M/sec                  
     4,683,190,628      branch-misses             #    1.27% of all branches        

    1959.902502230 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.82#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.82#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.82#

               Core t (s)   Wall t (s)        (%)
       Time:     1960.339     1960.339      100.0
                         32:40
                 (ns/day)    (hour/ns)
Performance:        6.611        3.630

GROMACS reminds you: "Njuta men inte frossa, springa men inte fly" (Paganus)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1962032.118879      task-clock (msec)         #    1.001 CPUs utilized          
             2,916      context-switches          #    0.001 K/sec                  
                45      cpu-migrations            #    0.000 K/sec                  
            92,188      page-faults               #    0.047 K/sec                  
 6,467,847,622,223      cycles                    #    3.297 GHz                    
13,528,428,294,353      instructions              #    2.09  insn per cycle         
   369,386,318,139      branches                  #  188.267 M/sec                  
     4,664,950,851      branch-misses             #    1.26% of all branches        

    1960.539539121 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.83#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.83#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.83#

               Core t (s)   Wall t (s)        (%)
       Time:     1964.950     1964.950      100.0
                         32:44
                 (ns/day)    (hour/ns)
Performance:        6.596        3.639

GROMACS reminds you: "I think everybody should like everybody." (Andy Warhol)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1966647.605379      task-clock (msec)         #    1.001 CPUs utilized          
             2,927      context-switches          #    0.001 K/sec                  
                43      cpu-migrations            #    0.000 K/sec                  
           126,358      page-faults               #    0.064 K/sec                  
 6,483,192,187,495      cycles                    #    3.297 GHz                    
13,529,886,488,542      instructions              #    2.09  insn per cycle         
   369,421,837,250      branches                  #  187.843 M/sec                  
     4,660,888,009      branch-misses             #    1.26% of all branches        

    1965.150394102 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.84#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.84#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.84#

               Core t (s)   Wall t (s)        (%)
       Time:     1966.665     1966.665      100.0
                         32:46
                 (ns/day)    (hour/ns)
Performance:        6.590        3.642

GROMACS reminds you: "Never measure the height of a mountain until you have reached the top. Then you will see how low it was." (Dag Hammarskjold)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1968381.422505      task-clock (msec)         #    1.001 CPUs utilized          
             2,924      context-switches          #    0.001 K/sec                  
                43      cpu-migrations            #    0.000 K/sec                  
           129,940      page-faults               #    0.066 K/sec                  
 6,488,638,689,767      cycles                    #    3.296 GHz                    
13,529,284,971,518      instructions              #    2.09  insn per cycle         
   369,424,376,873      branches                  #  187.679 M/sec                  
     4,679,733,145      branch-misses             #    1.27% of all branches        

    1966.881398433 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.85#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.85#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.85#

               Core t (s)   Wall t (s)        (%)
       Time:     1959.771     1959.771      100.0
                         32:39
                 (ns/day)    (hour/ns)
Performance:        6.613        3.629

GROMACS reminds you: "Is it the invisible chemistry stuff?" (Frida Hyvonen)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1961464.741293      task-clock (msec)         #    1.001 CPUs utilized          
             2,915      context-switches          #    0.001 K/sec                  
                39      cpu-migrations            #    0.000 K/sec                  
            70,153      page-faults               #    0.036 K/sec                  
 6,465,319,765,725      cycles                    #    3.296 GHz                    
13,530,828,170,268      instructions              #    2.09  insn per cycle         
   369,397,236,468      branches                  #  188.327 M/sec                  
     4,694,075,724      branch-misses             #    1.27% of all branches        

    1959.973454789 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.86#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.86#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.86#

               Core t (s)   Wall t (s)        (%)
       Time:     1962.395     1962.395      100.0
                         32:42
                 (ns/day)    (hour/ns)
Performance:        6.604        3.634

GROMACS reminds you: "May the Force Be With You" (Star Wars)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1964086.182788      task-clock (msec)         #    1.001 CPUs utilized          
             2,922      context-switches          #    0.001 K/sec                  
                49      cpu-migrations            #    0.000 K/sec                  
           100,802      page-faults               #    0.051 K/sec                  
 6,474,210,924,384      cycles                    #    3.296 GHz                    
13,529,944,057,543      instructions              #    2.09  insn per cycle         
   369,407,907,449      branches                  #  188.081 M/sec                  
     4,655,105,844      branch-misses             #    1.26% of all branches        

    1962.600370264 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.87#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.87#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.87#

               Core t (s)   Wall t (s)        (%)
       Time:     1966.112     1966.112      100.0
                         32:46
                 (ns/day)    (hour/ns)
Performance:        6.592        3.641

GROMACS reminds you: "Can someone please tell Icarus that he's not the only one falling from the sky?" (Urban Dance Squad)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1967815.383353      task-clock (msec)         #    1.001 CPUs utilized          
             2,925      context-switches          #    0.001 K/sec                  
                46      cpu-migrations            #    0.000 K/sec                  
           129,442      page-faults               #    0.066 K/sec                  
 6,486,714,201,461      cycles                    #    3.296 GHz                    
13,531,391,275,032      instructions              #    2.09  insn per cycle         
   369,432,245,967      branches                  #  187.737 M/sec                  
     4,665,249,935      branch-misses             #    1.26% of all branches        

    1966.312984621 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.88#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.88#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.88#

               Core t (s)   Wall t (s)        (%)
       Time:     1956.043     1956.043      100.0
                         32:36
                 (ns/day)    (hour/ns)
Performance:        6.626        3.622

GROMACS reminds you: "Clickety Clickety Click" (System Manager From Hell)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1957737.201690      task-clock (msec)         #    1.001 CPUs utilized          
             2,908      context-switches          #    0.001 K/sec                  
                46      cpu-migrations            #    0.000 K/sec                  
            41,241      page-faults               #    0.021 K/sec                  
 6,453,334,275,939      cycles                    #    3.296 GHz                    
13,530,454,455,998      instructions              #    2.10  insn per cycle         
   369,387,791,817      branches                  #  188.681 M/sec                  
     4,683,132,487      branch-misses             #    1.27% of all branches        

    1956.250165940 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.89#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0017.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.89#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.89#

               Core t (s)   Wall t (s)        (%)
       Time:     1958.706     1958.706      100.0
                         32:38
                 (ns/day)    (hour/ns)
Performance:        6.617        3.627

GROMACS reminds you: "Restraint! What possible restraint?" (Joseph Conrad)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1960394.333632      task-clock (msec)         #    1.001 CPUs utilized          
             2,910      context-switches          #    0.001 K/sec                  
                42      cpu-migrations            #    0.000 K/sec                  
            78,016      page-faults               #    0.040 K/sec                  
 6,462,253,787,270      cycles                    #    3.296 GHz                    
13,530,009,190,474      instructions              #    2.09  insn per cycle         
   369,389,269,521      branches                  #  188.426 M/sec                  
     4,659,850,480      branch-misses             #    1.26% of all branches        

    1958.895483190 seconds time elapsed

