                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.45#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.45#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.45#

               Core t (s)   Wall t (s)        (%)
       Time:      651.741      651.741      100.0
                 (ns/day)    (hour/ns)
Performance:        6.629        3.621

GROMACS reminds you: "It's So Fast It's Slow" (F. Black)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     652437.572751      task-clock (msec)         #    1.001 CPUs utilized          
             1,044      context-switches          #    0.002 K/sec                  
                15      cpu-migrations            #    0.000 K/sec                  
            64,346      page-faults               #    0.099 K/sec                  
 2,149,588,020,373      cycles                    #    3.295 GHz                    
 4,510,316,148,609      instructions              #    2.10  insn per cycle         
   123,212,882,954      branches                  #  188.850 M/sec                  
     1,568,658,272      branch-misses             #    1.27% of all branches        

     651.944755524 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.46#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.46#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.46#

               Core t (s)   Wall t (s)        (%)
       Time:      651.380      651.380      100.0
                 (ns/day)    (hour/ns)
Performance:        6.632        3.619

GROMACS reminds you: "Encountered Subspace Anomaly" (Star Trek)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     652070.572628      task-clock (msec)         #    1.001 CPUs utilized          
             1,049      context-switches          #    0.002 K/sec                  
                10      cpu-migrations            #    0.000 K/sec                  
            63,940      page-faults               #    0.098 K/sec                  
 2,148,614,782,628      cycles                    #    3.295 GHz                    
 4,510,341,889,700      instructions              #    2.10  insn per cycle         
   123,216,170,178      branches                  #  188.961 M/sec                  
     1,556,551,788      branch-misses             #    1.26% of all branches        

     651.582309983 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.47#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.47#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.47#

               Core t (s)   Wall t (s)        (%)
       Time:      651.530      651.530      100.0
                 (ns/day)    (hour/ns)
Performance:        6.631        3.619

GROMACS reminds you: "Shit Happens" (Pulp Fiction)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     652207.658610      task-clock (msec)         #    1.001 CPUs utilized          
             1,046      context-switches          #    0.002 K/sec                  
                12      cpu-migrations            #    0.000 K/sec                  
            60,819      page-faults               #    0.093 K/sec                  
 2,149,281,535,205      cycles                    #    3.295 GHz                    
 4,510,416,000,080      instructions              #    2.10  insn per cycle         
   123,216,918,309      branches                  #  188.923 M/sec                  
     1,561,921,925      branch-misses             #    1.27% of all branches        

     651.721168466 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.48#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.48#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.48#

               Core t (s)   Wall t (s)        (%)
       Time:      651.718      651.718      100.0
                 (ns/day)    (hour/ns)
Performance:        6.629        3.621

GROMACS reminds you: "Sort Of" (Urban Dance Squad)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     652416.632012      task-clock (msec)         #    1.001 CPUs utilized          
             1,051      context-switches          #    0.002 K/sec                  
                10      cpu-migrations            #    0.000 K/sec                  
            66,753      page-faults               #    0.102 K/sec                  
 2,150,054,764,140      cycles                    #    3.296 GHz                    
 4,509,731,055,337      instructions              #    2.10  insn per cycle         
   123,207,431,986      branches                  #  188.848 M/sec                  
     1,566,030,226      branch-misses             #    1.27% of all branches        

     651.925430493 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.49#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.49#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.49#

               Core t (s)   Wall t (s)        (%)
       Time:      651.011      651.011      100.0
                 (ns/day)    (hour/ns)
Performance:        6.636        3.617

GROMACS reminds you: "The determined Real Programmer can write FORTRAN programs in any language." (Ed Post)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     651702.495192      task-clock (msec)         #    1.001 CPUs utilized          
             1,043      context-switches          #    0.002 K/sec                  
                13      cpu-migrations            #    0.000 K/sec                  
            64,077      page-faults               #    0.098 K/sec                  
 2,147,594,389,854      cycles                    #    3.295 GHz                    
 4,510,803,339,270      instructions              #    2.10  insn per cycle         
   123,215,912,932      branches                  #  189.068 M/sec                  
     1,553,809,242      branch-misses             #    1.26% of all branches        

     651.215069125 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.50#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.50#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.50#

               Core t (s)   Wall t (s)        (%)
       Time:      655.667      655.667      100.0
                 (ns/day)    (hour/ns)
Performance:        6.589        3.642

GROMACS reminds you: "All You Need is Greed" (Aztec Camera)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     656326.062756      task-clock (msec)         #    1.001 CPUs utilized          
             1,052      context-switches          #    0.002 K/sec                  
                11      cpu-migrations            #    0.000 K/sec                  
            66,776      page-faults               #    0.102 K/sec                  
 2,163,590,937,758      cycles                    #    3.297 GHz                    
 4,509,648,683,062      instructions              #    2.08  insn per cycle         
   123,208,344,328      branches                  #  187.724 M/sec                  
     1,561,941,467      branch-misses             #    1.27% of all branches        

     655.846517134 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.51#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.51#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.51#

               Core t (s)   Wall t (s)        (%)
       Time:      655.886      655.886      100.0
                 (ns/day)    (hour/ns)
Performance:        6.587        3.644

GROMACS reminds you: "Everything He Lacks, He Makes Up In Denial" (Offspring)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     656574.463761      task-clock (msec)         #    1.001 CPUs utilized          
             1,049      context-switches          #    0.002 K/sec                  
                 8      cpu-migrations            #    0.000 K/sec                  
            66,926      page-faults               #    0.102 K/sec                  
 2,163,653,261,322      cycles                    #    3.295 GHz                    
 4,510,234,878,241      instructions              #    2.08  insn per cycle         
   123,215,154,808      branches                  #  187.664 M/sec                  
     1,554,830,473      branch-misses             #    1.26% of all branches        

     656.078308720 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.52#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.52#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.52#

               Core t (s)   Wall t (s)        (%)
       Time:      648.119      648.119      100.0
                 (ns/day)    (hour/ns)
Performance:        6.666        3.601

GROMACS reminds you: "The easiest way to scale well is to have bad single-core performance" (Blind Freddie)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     648803.142075      task-clock (msec)         #    1.001 CPUs utilized          
             1,045      context-switches          #    0.002 K/sec                  
                10      cpu-migrations            #    0.000 K/sec                  
            32,625      page-faults               #    0.050 K/sec                  
 2,138,009,744,277      cycles                    #    3.295 GHz                    
 4,509,841,728,128      instructions              #    2.11  insn per cycle         
   123,205,939,540      branches                  #  189.897 M/sec                  
     1,553,643,912      branch-misses             #    1.26% of all branches        

     648.319918362 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.53#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.53#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.53#

               Core t (s)   Wall t (s)        (%)
       Time:      651.443      651.443      100.0
                 (ns/day)    (hour/ns)
Performance:        6.632        3.619

GROMACS reminds you: "Carbohydrates is all they groove" (Frank Zappa)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     652124.538380      task-clock (msec)         #    1.001 CPUs utilized          
             1,047      context-switches          #    0.002 K/sec                  
                10      cpu-migrations            #    0.000 K/sec                  
            64,199      page-faults               #    0.098 K/sec                  
 2,148,957,027,633      cycles                    #    3.295 GHz                    
 4,511,850,935,720      instructions              #    2.10  insn per cycle         
   123,222,802,862      branches                  #  188.956 M/sec                  
     1,552,548,058      branch-misses             #    1.26% of all branches        

     651.637565449 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.54#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.54#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.54#

               Core t (s)   Wall t (s)        (%)
       Time:      670.704      670.704      100.0
                 (ns/day)    (hour/ns)
Performance:        6.441        3.726

GROMACS reminds you: "An expert is a person who has made all the mistakes that can be made in a very narrow field." (Niels Bohr)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     671414.891982      task-clock (msec)         #    1.001 CPUs utilized          
             1,073      context-switches          #    0.002 K/sec                  
                12      cpu-migrations            #    0.000 K/sec                  
            66,856      page-faults               #    0.100 K/sec                  
 2,212,455,461,536      cycles                    #    3.295 GHz                    
 4,509,775,354,835      instructions              #    2.04  insn per cycle         
   123,223,388,515      branches                  #  183.528 M/sec                  
     1,555,775,290      branch-misses             #    1.26% of all branches        

     670.909008578 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.55#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.55#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.55#

               Core t (s)   Wall t (s)        (%)
       Time:      654.208      654.208      100.0
                 (ns/day)    (hour/ns)
Performance:        6.604        3.634

GROMACS reminds you: "Never mind, death professor, your structure's fine" (TV on the Radio)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     654903.142979      task-clock (msec)         #    1.001 CPUs utilized          
             1,050      context-switches          #    0.002 K/sec                  
                16      cpu-migrations            #    0.000 K/sec                  
            67,283      page-faults               #    0.103 K/sec                  
 2,158,237,460,095      cycles                    #    3.296 GHz                    
 4,510,089,978,519      instructions              #    2.09  insn per cycle         
   123,214,524,356      branches                  #  188.142 M/sec                  
     1,560,384,291      branch-misses             #    1.27% of all branches        

     654.409294070 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.56#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.56#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.56#

               Core t (s)   Wall t (s)        (%)
       Time:      655.216      655.216      100.0
                 (ns/day)    (hour/ns)
Performance:        6.594        3.640

GROMACS reminds you: "Sort Of" (Urban Dance Squad)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     655905.359246      task-clock (msec)         #    1.001 CPUs utilized          
             1,058      context-switches          #    0.002 K/sec                  
                19      cpu-migrations            #    0.000 K/sec                  
            40,786      page-faults               #    0.062 K/sec                  
 2,161,342,243,734      cycles                    #    3.295 GHz                    
 4,510,434,060,038      instructions              #    2.09  insn per cycle         
   123,212,578,445      branches                  #  187.851 M/sec                  
     1,568,053,060      branch-misses             #    1.27% of all branches        

     655.419778696 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.57#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.57#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.57#

               Core t (s)   Wall t (s)        (%)
       Time:      662.822      662.822      100.0
                 (ns/day)    (hour/ns)
Performance:        6.518        3.682

GROMACS reminds you: "I Need a Little Poison" (Throwing Muses)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     663526.691369      task-clock (msec)         #    1.001 CPUs utilized          
             1,061      context-switches          #    0.002 K/sec                  
                17      cpu-migrations            #    0.000 K/sec                  
            67,109      page-faults               #    0.101 K/sec                  
 2,186,476,232,720      cycles                    #    3.295 GHz                    
 4,510,527,410,605      instructions              #    2.06  insn per cycle         
   123,227,261,838      branches                  #  185.716 M/sec                  
     1,558,998,565      branch-misses             #    1.27% of all branches        

     663.026546797 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.58#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.58#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.58#

               Core t (s)   Wall t (s)        (%)
       Time:      651.033      651.033      100.0
                 (ns/day)    (hour/ns)
Performance:        6.636        3.617

GROMACS reminds you: "All I Ever Wanted Was Your Life" (Red Hot Chili Peppers)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     651728.546230      task-clock (msec)         #    1.001 CPUs utilized          
             1,048      context-switches          #    0.002 K/sec                  
                19      cpu-migrations            #    0.000 K/sec                  
            63,984      page-faults               #    0.098 K/sec                  
 2,147,428,040,143      cycles                    #    3.295 GHz                    
 4,510,038,645,180      instructions              #    2.10  insn per cycle         
   123,210,843,922      branches                  #  189.052 M/sec                  
     1,560,303,681      branch-misses             #    1.27% of all branches        

     651.239506167 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.59#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.59#
starting mdrun 'Protein in water'
25000 steps,     50.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.59#

               Core t (s)   Wall t (s)        (%)
       Time:      662.738      662.738      100.0
                 (ns/day)    (hour/ns)
Performance:        6.519        3.682

GROMACS reminds you: "Isnt this enough? Just this world? Just this beautiful, complex wonderfully unfathomable world? How does it so fail to hold our attention that we have to diminish it with the invention of cheap, man-made myths and monsters?" (Tim Minchin)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     663439.576312      task-clock (msec)         #    1.001 CPUs utilized          
             1,059      context-switches          #    0.002 K/sec                  
                15      cpu-migrations            #    0.000 K/sec                  
            67,131      page-faults               #    0.101 K/sec                  
 2,186,145,466,339      cycles                    #    3.295 GHz                    
 4,510,062,036,126      instructions              #    2.06  insn per cycle         
   123,215,725,601      branches                  #  185.723 M/sec                  
     1,566,109,178      branch-misses             #    1.27% of all branches        

     662.941740037 seconds time elapsed

