                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.15#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.15#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.15#

               Core t (s)   Wall t (s)        (%)
       Time:      129.756      129.756      100.0
                 (ns/day)    (hour/ns)
Performance:        6.660        3.604

GROMACS reminds you: "I originally implemented PME to prove that you didn't need it..." (Erik Lindahl)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     130041.284679      task-clock (msec)         #    1.001 CPUs utilized          
               367      context-switches          #    0.003 K/sec                  
                 8      cpu-migrations            #    0.000 K/sec                  
            40,721      page-faults               #    0.313 K/sec                  
   427,595,079,693      cycles                    #    3.288 GHz                    
   902,481,338,665      instructions              #    2.11  insn per cycle         
    24,737,498,759      branches                  #  190.228 M/sec                  
       311,934,292      branch-misses             #    1.26% of all branches        

     129.960601722 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.16#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.16#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.16#

               Core t (s)   Wall t (s)        (%)
       Time:      129.595      129.595      100.0
                 (ns/day)    (hour/ns)
Performance:        6.668        3.599

GROMACS reminds you: "I'm Only Faking When I Get It Right" (Soundgarden)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129880.989646      task-clock (msec)         #    1.001 CPUs utilized          
               367      context-switches          #    0.003 K/sec                  
                 4      cpu-migrations            #    0.000 K/sec                  
            40,866      page-faults               #    0.315 K/sec                  
   427,109,384,415      cycles                    #    3.288 GHz                    
   902,596,619,801      instructions              #    2.11  insn per cycle         
    24,738,737,567      branches                  #  190.472 M/sec                  
       312,381,999      branch-misses             #    1.26% of all branches        

     129.804890734 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.17#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.17#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.17#

               Core t (s)   Wall t (s)        (%)
       Time:      130.706      130.706      100.0
                 (ns/day)    (hour/ns)
Performance:        6.612        3.630

GROMACS reminds you: "Science Won't Change You" (The Talking Heads)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129868.760720      task-clock (msec)         #    0.992 CPUs utilized          
               365      context-switches          #    0.003 K/sec                  
                 7      cpu-migrations            #    0.000 K/sec                  
            40,567      page-faults               #    0.312 K/sec                  
   426,994,620,924      cycles                    #    3.288 GHz                    
   902,634,163,403      instructions              #    2.11  insn per cycle         
    24,738,375,313      branches                  #  190.487 M/sec                  
       311,593,805      branch-misses             #    1.26% of all branches        

     130.913864479 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.18#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.18#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.18#

               Core t (s)   Wall t (s)        (%)
       Time:      129.497      129.497      100.0
                 (ns/day)    (hour/ns)
Performance:        6.673        3.596

GROMACS reminds you: "Never mind, death professor, your structure's fine" (TV on the Radio)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129777.491848      task-clock (msec)         #    1.001 CPUs utilized          
               368      context-switches          #    0.003 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            40,451      page-faults               #    0.312 K/sec                  
   426,706,549,740      cycles                    #    3.288 GHz                    
   902,538,362,570      instructions              #    2.12  insn per cycle         
    24,739,636,864      branches                  #  190.631 M/sec                  
       312,560,784      branch-misses             #    1.26% of all branches        

     129.699176320 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.19#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.19#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.19#

               Core t (s)   Wall t (s)        (%)
       Time:      129.721      129.721      100.0
                 (ns/day)    (hour/ns)
Performance:        6.662        3.603

GROMACS reminds you: "Boom Boom Boom Boom, I Want You in My Room" (Venga Boys)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129988.322200      task-clock (msec)         #    1.001 CPUs utilized          
               364      context-switches          #    0.003 K/sec                  
                 9      cpu-migrations            #    0.000 K/sec                  
            40,443      page-faults               #    0.311 K/sec                  
   427,424,265,880      cycles                    #    3.288 GHz                    
   902,214,971,173      instructions              #    2.11  insn per cycle         
    24,738,701,268      branches                  #  190.315 M/sec                  
       312,282,179      branch-misses             #    1.26% of all branches        

     129.908979174 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.20#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.20#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.20#

               Core t (s)   Wall t (s)        (%)
       Time:      129.579      129.579      100.0
                 (ns/day)    (hour/ns)
Performance:        6.669        3.599

GROMACS reminds you: "What Kind Of Guru are You, Anyway ?" (F. Zappa)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129857.972887      task-clock (msec)         #    1.001 CPUs utilized          
               369      context-switches          #    0.003 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            40,456      page-faults               #    0.312 K/sec                  
   427,104,951,263      cycles                    #    3.289 GHz                    
   902,513,970,220      instructions              #    2.11  insn per cycle         
    24,738,496,899      branches                  #  190.504 M/sec                  
       314,220,365      branch-misses             #    1.27% of all branches        

     129.776179281 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.21#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.21#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.21#

               Core t (s)   Wall t (s)        (%)
       Time:      129.493      129.493      100.0
                 (ns/day)    (hour/ns)
Performance:        6.674        3.596

GROMACS reminds you: "BioBeat is Not Available In Regular Shops" (P.J. Meulenhoff)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129769.239259      task-clock (msec)         #    1.001 CPUs utilized          
               361      context-switches          #    0.003 K/sec                  
                 5      cpu-migrations            #    0.000 K/sec                  
            40,815      page-faults               #    0.315 K/sec                  
   426,888,054,249      cycles                    #    3.290 GHz                    
   902,435,920,031      instructions              #    2.11  insn per cycle         
    24,737,697,475      branches                  #  190.628 M/sec                  
       313,157,485      branch-misses             #    1.27% of all branches        

     129.688369660 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.22#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.22#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.22#

               Core t (s)   Wall t (s)        (%)
       Time:      129.572      129.572      100.0
                 (ns/day)    (hour/ns)
Performance:        6.669        3.598

GROMACS reminds you: "Jesus Can't Save You, Though It's Nice to Think He Tried" (Black Crowes)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129845.822487      task-clock (msec)         #    1.001 CPUs utilized          
               367      context-switches          #    0.003 K/sec                  
                 4      cpu-migrations            #    0.000 K/sec                  
            40,464      page-faults               #    0.312 K/sec                  
   427,094,539,270      cycles                    #    3.289 GHz                    
   902,827,967,225      instructions              #    2.11  insn per cycle         
    24,738,485,287      branches                  #  190.522 M/sec                  
       312,670,684      branch-misses             #    1.26% of all branches        

     129.765654301 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.23#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.23#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.23#

               Core t (s)   Wall t (s)        (%)
       Time:      129.573      129.573      100.0
                 (ns/day)    (hour/ns)
Performance:        6.669        3.599

GROMACS reminds you: "Wicky-wicky Wa-wild West" (Will Smith)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129848.864155      task-clock (msec)         #    1.001 CPUs utilized          
               364      context-switches          #    0.003 K/sec                  
                 3      cpu-migrations            #    0.000 K/sec                  
            40,793      page-faults               #    0.314 K/sec                  
   427,100,034,744      cycles                    #    3.289 GHz                    
   902,781,998,216      instructions              #    2.11  insn per cycle         
    24,741,331,758      branches                  #  190.539 M/sec                  
       314,376,751      branch-misses             #    1.27% of all branches        

     129.768880730 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.24#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.24#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.24#

               Core t (s)   Wall t (s)        (%)
       Time:      129.731      129.731      100.0
                 (ns/day)    (hour/ns)
Performance:        6.661        3.603

GROMACS reminds you: "Chance favors the prepared mind." (Louis Pasteur)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129920.310680      task-clock (msec)         #    1.000 CPUs utilized          
               365      context-switches          #    0.003 K/sec                  
                 4      cpu-migrations            #    0.000 K/sec                  
            40,976      page-faults               #    0.315 K/sec                  
   427,164,113,930      cycles                    #    3.288 GHz                    
   902,194,675,712      instructions              #    2.11  insn per cycle         
    24,735,762,880      branches                  #  190.392 M/sec                  
       312,127,350      branch-misses             #    1.26% of all branches        

     129.933383624 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.25#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.25#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.25#

               Core t (s)   Wall t (s)        (%)
       Time:      129.511      129.511      100.0
                 (ns/day)    (hour/ns)
Performance:        6.673        3.597

GROMACS reminds you: "Give a Man a Fish" (Arrested Development)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129800.322728      task-clock (msec)         #    1.001 CPUs utilized          
               365      context-switches          #    0.003 K/sec                  
                 3      cpu-migrations            #    0.000 K/sec                  
            40,485      page-faults               #    0.312 K/sec                  
   426,833,624,130      cycles                    #    3.288 GHz                    
   902,659,079,343      instructions              #    2.11  insn per cycle         
    24,739,977,180      branches                  #  190.600 M/sec                  
       311,803,418      branch-misses             #    1.26% of all branches        

     129.720603776 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.26#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.26#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.26#

               Core t (s)   Wall t (s)        (%)
       Time:      129.545      129.545      100.0
                 (ns/day)    (hour/ns)
Performance:        6.671        3.598

GROMACS reminds you: "Interfacing Space and Beyond..." (P. J. Harvey)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129823.569338      task-clock (msec)         #    1.001 CPUs utilized          
               368      context-switches          #    0.003 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            40,452      page-faults               #    0.312 K/sec                  
   426,982,086,299      cycles                    #    3.289 GHz                    
   902,543,264,246      instructions              #    2.11  insn per cycle         
    24,737,510,464      branches                  #  190.547 M/sec                  
       313,896,501      branch-misses             #    1.27% of all branches        

     129.744299982 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.27#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.27#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.27#

               Core t (s)   Wall t (s)        (%)
       Time:      129.526      129.526      100.0
                 (ns/day)    (hour/ns)
Performance:        6.672        3.597

GROMACS reminds you: "During my undergraduate work I concluded that electrostatics is unlikely to be important [for enzymes]" (Arieh Warshel, Nobel lecture 2013)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129806.622891      task-clock (msec)         #    1.001 CPUs utilized          
               366      context-switches          #    0.003 K/sec                  
                 3      cpu-migrations            #    0.000 K/sec                  
            40,960      page-faults               #    0.316 K/sec                  
   426,983,308,982      cycles                    #    3.289 GHz                    
   902,173,500,452      instructions              #    2.11  insn per cycle         
    24,734,719,894      branches                  #  190.551 M/sec                  
       314,976,256      branch-misses             #    1.27% of all branches        

     129.725929739 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.28#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.28#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.28#

               Core t (s)   Wall t (s)        (%)
       Time:      129.638      129.638      100.0
                 (ns/day)    (hour/ns)
Performance:        6.666        3.600

GROMACS reminds you: "I Am the Psychotherapist. Please, Describe Your Problems." (GNU Emacs)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129922.326173      task-clock (msec)         #    1.001 CPUs utilized          
               367      context-switches          #    0.003 K/sec                  
                 6      cpu-migrations            #    0.000 K/sec                  
            40,444      page-faults               #    0.311 K/sec                  
   427,293,020,362      cycles                    #    3.289 GHz                    
   902,685,174,655      instructions              #    2.11  insn per cycle         
    24,740,911,323      branches                  #  190.428 M/sec                  
       312,636,552      branch-misses             #    1.26% of all branches        

     129.841744855 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.29#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host hal0010.amarel.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Compiled SIMD instructions: AVX_256, GROMACS could use AVX2_256 on this machine, which is better.

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.29#
starting mdrun 'Protein in water'
5000 steps,     10.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.29#

               Core t (s)   Wall t (s)        (%)
       Time:      129.559      129.559      100.0
                 (ns/day)    (hour/ns)
Performance:        6.670        3.598

GROMACS reminds you: "Let Me Do This" (Urban Dance Squad)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     129839.931320      task-clock (msec)         #    1.001 CPUs utilized          
               365      context-switches          #    0.003 K/sec                  
                 4      cpu-migrations            #    0.000 K/sec                  
            40,459      page-faults               #    0.312 K/sec                  
   427,043,617,604      cycles                    #    3.289 GHz                    
   902,253,345,800      instructions              #    2.11  insn per cycle         
    24,738,120,444      branches                  #  190.528 M/sec                  
       313,633,961      branch-misses             #    1.27% of all branches        

     129.760757840 seconds time elapsed

