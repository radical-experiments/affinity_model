                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.75#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.75#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.75#

               Core t (s)   Wall t (s)        (%)
       Time:     2543.136     2543.136      100.0
                         42:23
                 (ns/day)    (hour/ns)
Performance:        5.096        4.709

GROMACS reminds you: "I Live the Life They Wish They Did" (Tricky)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2542647.762094      task-clock (msec)         #    1.000 CPUs utilized          
           259,498      context-switches          #    0.102 K/sec                  
                58      cpu-migrations            #    0.000 K/sec                  
            94,383      page-faults               #    0.037 K/sec                  
 8,363,889,380,966      cycles                    #    3.289 GHz                    
 4,475,063,209,958      stalled-cycles-frontend   #   53.50% frontend cycles idle   
   797,320,085,390      stalled-cycles-backend    #    9.53% backend cycles idle    
13,730,568,416,917      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,722,970,360      branches                  #  147.375 M/sec                  
     5,515,758,022      branch-misses             #    1.47% of all branches        

    2543.283877054 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.76#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.76#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.76#

               Core t (s)   Wall t (s)        (%)
       Time:     2549.169     2549.169      100.0
                         42:29
                 (ns/day)    (hour/ns)
Performance:        5.084        4.721

GROMACS reminds you: "Would You Like to Be the Monster Tonight ?" (Captain Beefheart)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2548617.075704      task-clock (msec)         #    1.000 CPUs utilized          
           260,144      context-switches          #    0.102 K/sec                  
                51      cpu-migrations            #    0.000 K/sec                  
            89,993      page-faults               #    0.035 K/sec                  
 8,382,889,775,039      cycles                    #    3.289 GHz                    
 4,493,127,724,503      stalled-cycles-frontend   #   53.60% frontend cycles idle   
   806,911,504,940      stalled-cycles-backend    #    9.63% backend cycles idle    
13,730,847,753,726      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,719,156,317      branches                  #  147.028 M/sec                  
     5,520,915,408      branch-misses             #    1.47% of all branches        

    2549.320592385 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.77#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.77#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.77#

               Core t (s)   Wall t (s)        (%)
       Time:     2546.427     2546.427      100.0
                         42:26
                 (ns/day)    (hour/ns)
Performance:        5.090        4.716

GROMACS reminds you: "It's So Fast It's Slow" (F. Black)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2545892.336454      task-clock (msec)         #    1.000 CPUs utilized          
           259,836      context-switches          #    0.102 K/sec                  
                48      cpu-migrations            #    0.000 K/sec                  
            92,092      page-faults               #    0.036 K/sec                  
 8,373,992,364,538      cycles                    #    3.289 GHz                    
 4,484,740,222,781      stalled-cycles-frontend   #   53.56% frontend cycles idle   
   785,875,829,358      stalled-cycles-backend    #    9.38% backend cycles idle    
13,729,871,992,898      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,711,478,126      branches                  #  147.183 M/sec                  
     5,533,673,493      branch-misses             #    1.48% of all branches        

    2546.577581304 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.78#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.78#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.78#

               Core t (s)   Wall t (s)        (%)
       Time:     2549.916     2549.916      100.0
                         42:29
                 (ns/day)    (hour/ns)
Performance:        5.083        4.722

GROMACS reminds you: "Drugs are Bad, mmokay" (South Park)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2549362.529247      task-clock (msec)         #    1.000 CPUs utilized          
           260,199      context-switches          #    0.102 K/sec                  
                55      cpu-migrations            #    0.000 K/sec                  
            97,589      page-faults               #    0.038 K/sec                  
 8,385,709,596,692      cycles                    #    3.289 GHz                    
 4,496,846,949,188      stalled-cycles-frontend   #   53.63% frontend cycles idle   
   793,856,119,506      stalled-cycles-backend    #    9.47% backend cycles idle    
13,728,474,933,257      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,702,258,991      branches                  #  146.979 M/sec                  
     5,564,646,679      branch-misses             #    1.49% of all branches        

    2550.065575217 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.79#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.79#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.79#

               Core t (s)   Wall t (s)        (%)
       Time:     2547.845     2547.845      100.0
                         42:27
                 (ns/day)    (hour/ns)
Performance:        5.087        4.718

GROMACS reminds you: "Every Sperm is Sacred" (Monty Python)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2547292.927181      task-clock (msec)         #    1.000 CPUs utilized          
           259,978      context-switches          #    0.102 K/sec                  
                55      cpu-migrations            #    0.000 K/sec                  
           118,147      page-faults               #    0.046 K/sec                  
 8,378,044,384,331      cycles                    #    3.289 GHz                    
 4,488,275,046,058      stalled-cycles-frontend   #   53.57% frontend cycles idle   
   808,806,875,351      stalled-cycles-backend    #    9.65% backend cycles idle    
13,729,792,745,323      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,724,069,299      branches                  #  147.107 M/sec                  
     5,540,907,255      branch-misses             #    1.48% of all branches        

    2547.995438705 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.80#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.80#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.80#

               Core t (s)   Wall t (s)        (%)
       Time:     2551.172     2551.172      100.0
                         42:31
                 (ns/day)    (hour/ns)
Performance:        5.080        4.724

GROMACS reminds you: "It's So Lonely When You Don't Even Know Yourself" (Red Hot Chili Peppers)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2550594.855599      task-clock (msec)         #    1.000 CPUs utilized          
           260,320      context-switches          #    0.102 K/sec                  
                59      cpu-migrations            #    0.000 K/sec                  
           115,482      page-faults               #    0.045 K/sec                  
 8,389,543,298,430      cycles                    #    3.289 GHz                    
 4,499,618,642,442      stalled-cycles-frontend   #   53.63% frontend cycles idle   
   808,274,587,906      stalled-cycles-backend    #    9.63% backend cycles idle    
13,731,368,601,865      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,743,633,814      branches                  #  146.924 M/sec                  
     5,543,614,574      branch-misses             #    1.48% of all branches        

    2551.319917083 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.81#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.81#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.81#

               Core t (s)   Wall t (s)        (%)
       Time:     2713.110     2713.110      100.0
                         45:13
                 (ns/day)    (hour/ns)
Performance:        4.777        5.024

GROMACS reminds you: "We All Get the Flu, We All Get Aids" (LIVE)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2712537.716794      task-clock (msec)         #    1.000 CPUs utilized          
           276,860      context-switches          #    0.102 K/sec                  
                59      cpu-migrations            #    0.000 K/sec                  
           118,426      page-faults               #    0.044 K/sec                  
 8,922,291,800,177      cycles                    #    3.289 GHz                    
 5,034,184,129,794      stalled-cycles-frontend   #   56.42% frontend cycles idle   
 1,077,740,729,219      stalled-cycles-backend    #   12.08% backend cycles idle    
13,730,617,865,861      instructions              #    1.54  insn per cycle         
                                                  #    0.37  stalled cycles per insn
   374,817,705,551      branches                  #  138.180 M/sec                  
     5,528,020,783      branch-misses             #    1.47% of all branches        

    2713.259374397 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.82#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.82#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.82#

               Core t (s)   Wall t (s)        (%)
       Time:     2549.012     2549.012      100.0
                         42:29
                 (ns/day)    (hour/ns)
Performance:        5.084        4.720

GROMACS reminds you: "If mathematical analysis should ever hold a prominent place in chemistry - an aberration which is happily almost impossible - it would occasion a rapid and widespread degeneration of that science." (Aguste Comte, 1830)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2548476.905986      task-clock (msec)         #    1.000 CPUs utilized          
           260,100      context-switches          #    0.102 K/sec                  
                49      cpu-migrations            #    0.000 K/sec                  
           120,292      page-faults               #    0.047 K/sec                  
 8,382,685,773,421      cycles                    #    3.289 GHz                    
 4,493,481,618,500      stalled-cycles-frontend   #   53.60% frontend cycles idle   
   790,385,762,402      stalled-cycles-backend    #    9.43% backend cycles idle    
13,729,546,752,814      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,719,822,718      branches                  #  147.037 M/sec                  
     5,539,190,872      branch-misses             #    1.48% of all branches        

    2549.161979865 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.83#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.83#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.83#

               Core t (s)   Wall t (s)        (%)
       Time:     2547.114     2547.114      100.0
                         42:27
                 (ns/day)    (hour/ns)
Performance:        5.088        4.717

GROMACS reminds you: "In the End Science Comes Down to Praying" (P. v.d. Berg)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2546571.375960      task-clock (msec)         #    1.000 CPUs utilized          
           259,910      context-switches          #    0.102 K/sec                  
                50      cpu-migrations            #    0.000 K/sec                  
           126,105      page-faults               #    0.050 K/sec                  
 8,376,160,089,727      cycles                    #    3.289 GHz                    
 4,487,158,811,203      stalled-cycles-frontend   #   53.57% frontend cycles idle   
   803,171,543,501      stalled-cycles-backend    #    9.59% backend cycles idle    
13,729,940,982,417      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,710,331,266      branches                  #  147.143 M/sec                  
     5,541,493,450      branch-misses             #    1.48% of all branches        

    2547.260404221 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.84#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.84#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.84#

               Core t (s)   Wall t (s)        (%)
       Time:     2757.726     2757.726      100.0
                         45:57
                 (ns/day)    (hour/ns)
Performance:        4.700        5.107

GROMACS reminds you: "I Live the Life They Wish They Did" (Tricky)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2757130.444929      task-clock (msec)         #    1.000 CPUs utilized          
           281,371      context-switches          #    0.102 K/sec                  
                63      cpu-migrations            #    0.000 K/sec                  
           133,099      page-faults               #    0.048 K/sec                  
 9,068,921,594,565      cycles                    #    3.289 GHz                    
 5,179,570,666,602      stalled-cycles-frontend   #   57.11% frontend cycles idle   
 1,121,730,855,661      stalled-cycles-backend    #   12.37% backend cycles idle    
13,731,522,459,758      instructions              #    1.51  insn per cycle         
                                                  #    0.38  stalled cycles per insn
   374,866,715,273      branches                  #  135.963 M/sec                  
     5,539,899,907      branch-misses             #    1.48% of all branches        

    2757.872371522 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.85#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.85#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.85#

               Core t (s)   Wall t (s)        (%)
       Time:     2544.995     2544.995      100.0
                         42:24
                 (ns/day)    (hour/ns)
Performance:        5.092        4.713

GROMACS reminds you: "I'm no model lady. A model's just an imitation of the real thing." (Mae West)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2544478.274343      task-clock (msec)         #    1.000 CPUs utilized          
           259,692      context-switches          #    0.102 K/sec                  
                54      cpu-migrations            #    0.000 K/sec                  
           131,201      page-faults               #    0.052 K/sec                  
 8,369,363,274,148      cycles                    #    3.289 GHz                    
 4,478,936,217,994      stalled-cycles-frontend   #   53.52% frontend cycles idle   
   800,155,018,645      stalled-cycles-backend    #    9.56% backend cycles idle    
13,732,444,854,987      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,732,044,574      branches                  #  147.273 M/sec                  
     5,570,969,459      branch-misses             #    1.49% of all branches        

    2545.140057213 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.86#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.86#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.86#

               Core t (s)   Wall t (s)        (%)
       Time:     2546.664     2546.664      100.0
                         42:26
                 (ns/day)    (hour/ns)
Performance:        5.089        4.716

GROMACS reminds you: "I Don't Like Dirt" (The Breeders)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2546139.178818      task-clock (msec)         #    1.000 CPUs utilized          
           259,885      context-switches          #    0.102 K/sec                  
                56      cpu-migrations            #    0.000 K/sec                  
           135,526      page-faults               #    0.053 K/sec                  
 8,373,919,195,079      cycles                    #    3.289 GHz                    
 4,483,734,762,530      stalled-cycles-frontend   #   53.54% frontend cycles idle   
   802,035,533,179      stalled-cycles-backend    #    9.58% backend cycles idle    
13,731,101,460,234      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,731,409,954      branches                  #  147.176 M/sec                  
     5,549,289,435      branch-misses             #    1.48% of all branches        

    2546.813954050 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.87#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.87#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.87#

               Core t (s)   Wall t (s)        (%)
       Time:     2551.329     2551.329      100.0
                         42:31
                 (ns/day)    (hour/ns)
Performance:        5.080        4.725

GROMACS reminds you: "Stay Cool, This is a Robbery" (Pulp Fiction)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2550810.342104      task-clock (msec)         #    1.000 CPUs utilized          
           260,334      context-switches          #    0.102 K/sec                  
                49      cpu-migrations            #    0.000 K/sec                  
           143,026      page-faults               #    0.056 K/sec                  
 8,390,316,274,950      cycles                    #    3.289 GHz                    
 4,502,109,643,293      stalled-cycles-frontend   #   53.66% frontend cycles idle   
   811,849,356,834      stalled-cycles-backend    #    9.68% backend cycles idle    
13,730,253,558,539      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,720,648,453      branches                  #  146.903 M/sec                  
     5,508,278,703      branch-misses             #    1.47% of all branches        

    2551.482490718 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.88#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.88#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.88#

               Core t (s)   Wall t (s)        (%)
       Time:     2554.870     2554.870      100.0
                         42:34
                 (ns/day)    (hour/ns)
Performance:        5.073        4.731

GROMACS reminds you: "Big Data is like teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing it, so everyone claims they are doing it..." (Dan Ariely)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2554318.575321      task-clock (msec)         #    1.000 CPUs utilized          
           260,701      context-switches          #    0.102 K/sec                  
                62      cpu-migrations            #    0.000 K/sec                  
           149,473      page-faults               #    0.059 K/sec                  
 8,401,477,745,220      cycles                    #    3.289 GHz                    
 4,510,667,353,656      stalled-cycles-frontend   #   53.69% frontend cycles idle   
   820,049,910,322      stalled-cycles-backend    #    9.76% backend cycles idle    
13,731,793,717,670      instructions              #    1.63  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,739,484,170      branches                  #  146.708 M/sec                  
     5,536,085,113      branch-misses             #    1.48% of all branches        

    2555.021679480 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.89#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.89#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.89#

               Core t (s)   Wall t (s)        (%)
       Time:     2552.385     2552.385      100.0
                         42:32
                 (ns/day)    (hour/ns)
Performance:        5.078        4.727

GROMACS reminds you: "There was no preconception on what to do" (Daft Punk)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2551845.329093      task-clock (msec)         #    1.000 CPUs utilized          
           260,440      context-switches          #    0.102 K/sec                  
                54      cpu-migrations            #    0.000 K/sec                  
           155,076      page-faults               #    0.061 K/sec                  
 8,393,550,550,779      cycles                    #    3.289 GHz                    
 4,503,044,715,796      stalled-cycles-frontend   #   53.65% frontend cycles idle   
   818,087,595,053      stalled-cycles-backend    #    9.75% backend cycles idle    
13,732,457,309,519      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   374,764,645,445      branches                  #  146.860 M/sec                  
     5,538,218,580      branch-misses             #    1.48% of all branches        

    2552.533470091 seconds time elapsed

