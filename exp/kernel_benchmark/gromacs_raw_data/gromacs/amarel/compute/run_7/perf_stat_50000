                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.60#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.60#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.60#

               Core t (s)   Wall t (s)        (%)
       Time:     1698.946     1698.946      100.0
                 (ns/day)    (hour/ns)
Performance:        5.086        4.719

GROMACS reminds you: "England's dancing days are done" (P. J. Harvey)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1698612.285280      task-clock (msec)         #    1.000 CPUs utilized          
           173,489      context-switches          #    0.102 K/sec                  
                38      cpu-migrations            #    0.000 K/sec                  
           116,717      page-faults               #    0.069 K/sec                  
 5,587,126,853,923      cycles                    #    3.289 GHz                    
 2,994,023,300,014      stalled-cycles-frontend   #   53.59% frontend cycles idle   
   543,200,563,023      stalled-cycles-backend    #    9.72% backend cycles idle    
 9,153,259,721,015      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   249,851,779,489      branches                  #  147.092 M/sec                  
     3,705,296,626      branch-misses             #    1.48% of all branches        

    1699.094074094 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.61#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.61#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.61#

               Core t (s)   Wall t (s)        (%)
       Time:     1693.410     1693.410      100.0
                 (ns/day)    (hour/ns)
Performance:        5.102        4.704

GROMACS reminds you: "Your Shopping Techniques are Amazing" (Gogol Bordello)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1693086.815961      task-clock (msec)         #    1.000 CPUs utilized          
           172,927      context-switches          #    0.102 K/sec                  
                41      cpu-migrations            #    0.000 K/sec                  
            78,140      page-faults               #    0.046 K/sec                  
 5,568,735,084,287      cycles                    #    3.289 GHz                    
 2,975,616,934,267      stalled-cycles-frontend   #   53.43% frontend cycles idle   
   530,370,989,128      stalled-cycles-backend    #    9.52% backend cycles idle    
 9,153,912,061,872      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   249,856,117,935      branches                  #  147.574 M/sec                  
     3,692,995,748      branch-misses             #    1.48% of all branches        

    1693.565780496 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.62#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.62#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.62#

               Core t (s)   Wall t (s)        (%)
       Time:     1701.638     1701.638      100.0
                 (ns/day)    (hour/ns)
Performance:        5.078        4.727

GROMACS reminds you: "I like to wait, then I feel like I do something" (Carl Caleman)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1701305.548052      task-clock (msec)         #    1.000 CPUs utilized          
           173,764      context-switches          #    0.102 K/sec                  
                31      cpu-migrations            #    0.000 K/sec                  
           115,202      page-faults               #    0.068 K/sec                  
 5,596,239,827,945      cycles                    #    3.289 GHz                    
 3,002,891,100,807      stalled-cycles-frontend   #   53.66% frontend cycles idle   
   551,262,654,978      stalled-cycles-backend    #    9.85% backend cycles idle    
 9,154,687,187,065      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   249,860,278,034      branches                  #  146.864 M/sec                  
     3,689,713,189      branch-misses             #    1.48% of all branches        

    1701.789152094 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.63#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.63#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.63#

               Core t (s)   Wall t (s)        (%)
       Time:     1692.329     1692.329      100.0
                 (ns/day)    (hour/ns)
Performance:        5.105        4.701

GROMACS reminds you: "Molecular biology is essentially the practice of biochemistry without a license." (Edwin Chargaff)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1692014.533295      task-clock (msec)         #    1.000 CPUs utilized          
           172,849      context-switches          #    0.102 K/sec                  
                42      cpu-migrations            #    0.000 K/sec                  
            34,847      page-faults               #    0.021 K/sec                  
 5,565,647,792,559      cycles                    #    3.289 GHz                    
 2,972,681,101,700      stalled-cycles-frontend   #   53.41% frontend cycles idle   
   515,898,000,919      stalled-cycles-backend    #    9.27% backend cycles idle    
 9,153,025,160,009      instructions              #    1.64  insn per cycle         
                                                  #    0.32  stalled cycles per insn
   249,840,018,504      branches                  #  147.658 M/sec                  
     3,684,655,449      branch-misses             #    1.47% of all branches        

    1692.497625046 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.64#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.64#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.64#

               Core t (s)   Wall t (s)        (%)
       Time:     1698.075     1698.075      100.0
                 (ns/day)    (hour/ns)
Performance:        5.088        4.717

GROMACS reminds you: "The Internet?  We are not interested in it." (Bill Gates, 1993)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1697764.218901      task-clock (msec)         #    1.000 CPUs utilized          
           173,400      context-switches          #    0.102 K/sec                  
                52      cpu-migrations            #    0.000 K/sec                  
            83,251      page-faults               #    0.049 K/sec                  
 5,584,747,958,485      cycles                    #    3.289 GHz                    
 2,991,791,874,634      stalled-cycles-frontend   #   53.57% frontend cycles idle   
   537,031,711,757      stalled-cycles-backend    #    9.62% backend cycles idle    
 9,152,646,826,723      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   249,836,656,305      branches                  #  147.156 M/sec                  
     3,691,582,280      branch-misses             #    1.48% of all branches        

    1698.223746017 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.65#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.65#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.65#

               Core t (s)   Wall t (s)        (%)
       Time:     1698.182     1698.182      100.0
                 (ns/day)    (hour/ns)
Performance:        5.088        4.717

GROMACS reminds you: "The determined Real Programmer can write FORTRAN programs in any language." (Ed Post)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1697870.143659      task-clock (msec)         #    1.000 CPUs utilized          
           173,409      context-switches          #    0.102 K/sec                  
                39      cpu-migrations            #    0.000 K/sec                  
           116,245      page-faults               #    0.068 K/sec                  
 5,585,083,968,958      cycles                    #    3.289 GHz                    
 2,991,990,295,645      stalled-cycles-frontend   #   53.57% frontend cycles idle   
   543,451,972,530      stalled-cycles-backend    #    9.73% backend cycles idle    
 9,153,610,699,633      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   249,848,557,954      branches                  #  147.154 M/sec                  
     3,686,251,369      branch-misses             #    1.48% of all branches        

    1698.330377254 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.66#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.66#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.66#

               Core t (s)   Wall t (s)        (%)
       Time:     1801.544     1801.544      100.0
                         30:01
                 (ns/day)    (hour/ns)
Performance:        4.796        5.004

GROMACS reminds you: "How will I know it's working right?" (MGMT)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1801194.324328      task-clock (msec)         #    1.000 CPUs utilized          
           183,983      context-switches          #    0.102 K/sec                  
                47      cpu-migrations            #    0.000 K/sec                  
            68,170      page-faults               #    0.038 K/sec                  
 5,924,232,262,424      cycles                    #    3.289 GHz                    
 3,331,970,451,722      stalled-cycles-frontend   #   56.24% frontend cycles idle   
   705,208,971,475      stalled-cycles-backend    #   11.90% backend cycles idle    
 9,153,340,655,890      instructions              #    1.55  insn per cycle         
                                                  #    0.36  stalled cycles per insn
   249,933,661,950      branches                  #  138.760 M/sec                  
     3,692,772,323      branch-misses             #    1.48% of all branches        

    1801.697086630 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.67#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.67#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.67#

               Core t (s)   Wall t (s)        (%)
       Time:     1694.447     1694.447      100.0
                 (ns/day)    (hour/ns)
Performance:        5.099        4.707

GROMACS reminds you: "Humbug! Most things free-born will submit to anything for a salary" (Mr. Rochester in Jane Eyre by Charlotte Bronte)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1694141.397831      task-clock (msec)         #    1.000 CPUs utilized          
           173,040      context-switches          #    0.102 K/sec                  
                33      cpu-migrations            #    0.000 K/sec                  
            94,616      page-faults               #    0.056 K/sec                  
 5,572,370,651,940      cycles                    #    3.289 GHz                    
 2,978,829,004,449      stalled-cycles-frontend   #   53.46% frontend cycles idle   
   533,133,355,504      stalled-cycles-backend    #    9.57% backend cycles idle    
 9,154,474,942,301      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   249,855,492,441      branches                  #  147.482 M/sec                  
     3,697,429,649      branch-misses             #    1.48% of all branches        

    1694.598971551 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.68#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.68#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.68#

               Core t (s)   Wall t (s)        (%)
       Time:     1702.248     1702.248      100.0
                 (ns/day)    (hour/ns)
Performance:        5.076        4.728

GROMACS reminds you: "There's only music to make new ringtones" (Arctic Monkeys)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1701942.620139      task-clock (msec)         #    1.000 CPUs utilized          
           173,828      context-switches          #    0.102 K/sec                  
                38      cpu-migrations            #    0.000 K/sec                  
           116,762      page-faults               #    0.069 K/sec                  
 5,597,889,741,061      cycles                    #    3.289 GHz                    
 3,004,583,739,058      stalled-cycles-frontend   #   53.67% frontend cycles idle   
   547,822,247,334      stalled-cycles-backend    #    9.79% backend cycles idle    
 9,154,507,643,988      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   249,868,654,433      branches                  #  146.814 M/sec                  
     3,696,727,071      branch-misses             #    1.48% of all branches        

    1702.395305306 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.69#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.69#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.69#

               Core t (s)   Wall t (s)        (%)
       Time:     1695.732     1695.732      100.0
                 (ns/day)    (hour/ns)
Performance:        5.095        4.710

GROMACS reminds you: "You Fill Your Space So Sweet" (F. Apple)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1695418.516707      task-clock (msec)         #    1.000 CPUs utilized          
           173,161      context-switches          #    0.102 K/sec                  
                37      cpu-migrations            #    0.000 K/sec                  
            72,385      page-faults               #    0.043 K/sec                  
 5,576,608,283,995      cycles                    #    3.289 GHz                    
 2,983,522,882,371      stalled-cycles-frontend   #   53.50% frontend cycles idle   
   531,324,923,257      stalled-cycles-backend    #    9.53% backend cycles idle    
 9,154,114,329,575      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   249,855,098,864      branches                  #  147.371 M/sec                  
     3,696,542,152      branch-misses             #    1.48% of all branches        

    1695.883565566 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.70#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.70#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.70#

               Core t (s)   Wall t (s)        (%)
       Time:     1704.601     1704.601      100.0
                 (ns/day)    (hour/ns)
Performance:        5.069        4.735

GROMACS reminds you: "You Crashed Into the Swamps" (Silicon Graphics)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1704265.604909      task-clock (msec)         #    1.000 CPUs utilized          
           174,065      context-switches          #    0.102 K/sec                  
                35      cpu-migrations            #    0.000 K/sec                  
           105,437      page-faults               #    0.062 K/sec                  
 5,605,354,597,904      cycles                    #    3.289 GHz                    
 3,011,998,716,838      stalled-cycles-frontend   #   53.73% frontend cycles idle   
   560,096,491,385      stalled-cycles-backend    #    9.99% backend cycles idle    
 9,155,182,478,128      instructions              #    1.63  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   249,873,959,881      branches                  #  146.617 M/sec                  
     3,685,626,952      branch-misses             #    1.47% of all branches        

    1704.747473008 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.71#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.71#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.71#

               Core t (s)   Wall t (s)        (%)
       Time:     1734.207     1734.207      100.0
                 (ns/day)    (hour/ns)
Performance:        4.982        4.817

GROMACS reminds you: "If everything seems under control, you're just not going fast enough." (Mario Andretti)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1733898.157167      task-clock (msec)         #    1.000 CPUs utilized          
           177,109      context-switches          #    0.102 K/sec                  
                37      cpu-migrations            #    0.000 K/sec                  
           119,589      page-faults               #    0.069 K/sec                  
 5,703,416,354,019      cycles                    #    3.289 GHz                    
 3,109,879,791,213      stalled-cycles-frontend   #   54.53% frontend cycles idle   
   578,275,542,283      stalled-cycles-backend    #   10.14% backend cycles idle    
 9,154,265,940,441      instructions              #    1.61  insn per cycle         
                                                  #    0.34  stalled cycles per insn
   249,894,001,496      branches                  #  144.123 M/sec                  
     3,703,815,203      branch-misses             #    1.48% of all branches        

    1734.356137559 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.72#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.72#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.72#

               Core t (s)   Wall t (s)        (%)
       Time:     1693.020     1693.020      100.0
                 (ns/day)    (hour/ns)
Performance:        5.103        4.703

GROMACS reminds you: "I think everybody should like everybody." (Andy Warhol)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1692698.646165      task-clock (msec)         #    1.000 CPUs utilized          
           172,885      context-switches          #    0.102 K/sec                  
                40      cpu-migrations            #    0.000 K/sec                  
            81,522      page-faults               #    0.048 K/sec                  
 5,567,602,956,363      cycles                    #    3.289 GHz                    
 2,975,274,755,203      stalled-cycles-frontend   #   53.44% frontend cycles idle   
   527,490,480,457      stalled-cycles-backend    #    9.47% backend cycles idle    
 9,152,973,108,656      instructions              #    1.64  insn per cycle         
                                                  #    0.33  stalled cycles per insn
   249,833,461,444      branches                  #  147.595 M/sec                  
     3,690,746,486      branch-misses             #    1.48% of all branches        

    1693.167724229 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.73#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.73#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.73#

               Core t (s)   Wall t (s)        (%)
       Time:     1736.372     1736.372      100.0
                 (ns/day)    (hour/ns)
Performance:        4.976        4.823

GROMACS reminds you: "It's Time to Move On" (F. Black)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1736019.269628      task-clock (msec)         #    1.000 CPUs utilized          
           177,302      context-switches          #    0.102 K/sec                  
                42      cpu-migrations            #    0.000 K/sec                  
           119,102      page-faults               #    0.069 K/sec                  
 5,710,154,825,405      cycles                    #    3.289 GHz                    
 3,116,763,842,018      stalled-cycles-frontend   #   54.58% frontend cycles idle   
   584,310,740,479      stalled-cycles-backend    #   10.23% backend cycles idle    
 9,154,157,722,358      instructions              #    1.60  insn per cycle         
                                                  #    0.34  stalled cycles per insn
   249,874,943,459      branches                  #  143.936 M/sec                  
     3,690,973,426      branch-misses             #    1.48% of all branches        

    1736.520812435 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.1 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.1
Executable:   /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1/bin/gmx_mpi
Data prefix:  /opt/sw/packages/intel-17.0.1/mvapich2-2.2/gromacs/2016.1
Working dir:  /scratch/mingtha/bin/gromacs/run_7
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.74#

Running on 1 node with total 16 cores, 16 logical cores
Hardware detected on host slepner006.hpcc.rutgers.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
    SIMD instructions most likely to fit this hardware: AVX_256
    SIMD instructions selected at GROMACS compile time: AVX_256

  Hardware topology: Basic

Reading file out.tpr, VERSION 2016.1 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.74#
starting mdrun 'Protein in water'
50000 steps,    100.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.74#

               Core t (s)   Wall t (s)        (%)
       Time:     1830.580     1830.580      100.0
                         30:30
                 (ns/day)    (hour/ns)
Performance:        4.720        5.085

GROMACS reminds you: "If I Wanted You to Understand This, I Would Explain it Better" (J. Cruijff)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    1830239.989534      task-clock (msec)         #    1.000 CPUs utilized          
           186,914      context-switches          #    0.102 K/sec                  
                42      cpu-migrations            #    0.000 K/sec                  
            33,518      page-faults               #    0.018 K/sec                  
 6,020,365,524,261      cycles                    #    3.289 GHz                    
 3,427,226,490,458      stalled-cycles-frontend   #   56.93% frontend cycles idle   
   734,571,766,669      stalled-cycles-backend    #   12.20% backend cycles idle    
 9,153,903,487,717      instructions              #    1.52  insn per cycle         
                                                  #    0.37  stalled cycles per insn
   249,921,641,764      branches                  #  136.551 M/sec                  
     3,698,239,239      branch-misses             #    1.48% of all branches        

    1830.726805099 seconds time elapsed

