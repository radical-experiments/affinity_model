                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.75#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.75#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.75#

               Core t (s)   Wall t (s)        (%)
       Time:     2746.803     2746.803      100.0
                         45:46
                 (ns/day)    (hour/ns)
Performance:        4.718        5.087

GROMACS reminds you: "This really is a pretty scene, could you ask your kid to smile please?" (Joe Jackson)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2724291.171922      task-clock (msec)         #    0.992 CPUs utilized          
           281,946      context-switches          #    0.103 K/sec                  
            15,899      cpu-migrations            #    0.006 K/sec                  
           168,882      page-faults               #    0.062 K/sec                  
 6,897,518,462,596      cycles                    #    2.532 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
12,995,989,331,399      instructions              #    1.88  insns per cycle        
   233,419,285,094      branches                  #   85.681 M/sec                  
     4,945,830,575      branch-misses             #    2.12% of all branches        

    2747.627665419 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.76#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.76#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.76#

               Core t (s)   Wall t (s)        (%)
       Time:     2742.233     2742.233      100.0
                         45:42
                 (ns/day)    (hour/ns)
Performance:        4.726        5.078

GROMACS reminds you: "You Can Be Too Early, You Can Be Too Late and You Can Be On Time" (J. Cruijff)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2720174.033223      task-clock (msec)         #    0.992 CPUs utilized          
           281,570      context-switches          #    0.104 K/sec                  
            15,105      cpu-migrations            #    0.006 K/sec                  
           105,920      page-faults               #    0.039 K/sec                  
 6,899,000,936,984      cycles                    #    2.536 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
12,996,304,757,204      instructions              #    1.88  insns per cycle        
   233,449,400,000      branches                  #   85.821 M/sec                  
     4,931,563,065      branch-misses             #    2.11% of all branches        

    2743.046374619 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.77#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.77#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.77#

               Core t (s)   Wall t (s)        (%)
       Time:     2766.278     2766.278      100.0
                         46:06
                 (ns/day)    (hour/ns)
Performance:        4.685        5.123

GROMACS reminds you: "I spent a lot of money on booze, birds and fast cars. The rest I just squandered." (George Best)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2743828.483224      task-clock (msec)         #    0.992 CPUs utilized          
           284,507      context-switches          #    0.104 K/sec                  
            15,001      cpu-migrations            #    0.005 K/sec                  
           166,301      page-faults               #    0.061 K/sec                  
 6,946,394,374,042      cycles                    #    2.532 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,079,604,379,295      instructions              #    1.88  insns per cycle        
   241,268,596,764      branches                  #   87.931 M/sec                  
     5,472,241,253      branch-misses             #    2.27% of all branches        

    2767.068733029 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.78#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.78#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.1#

               Core t (s)   Wall t (s)        (%)
       Time:     2783.034     2783.034      100.0
                         46:23
                 (ns/day)    (hour/ns)
Performance:        4.657        5.154

GROMACS reminds you: "Money won't buy happiness, but it will pay the salaries of a large research staff to study the problem." (Bill Vaughan)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2760814.973134      task-clock (msec)         #    0.992 CPUs utilized          
           285,399      context-switches          #    0.103 K/sec                  
            15,336      cpu-migrations            #    0.006 K/sec                  
           172,098      page-faults               #    0.062 K/sec                  
 7,003,332,867,616      cycles                    #    2.537 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,360,611,426,232      instructions              #    1.91  insns per cycle        
   244,345,586,389      branches                  #   88.505 M/sec                  
     5,272,190,639      branch-misses             #    2.16% of all branches        

    2783.860759538 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.1#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.1#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.2#

               Core t (s)   Wall t (s)        (%)
       Time:     2749.864     2749.864      100.0
                         45:49
                 (ns/day)    (hour/ns)
Performance:        4.713        5.092

GROMACS reminds you: "You're About to Hurt Somebody" (Jazzy Jeff)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2727663.791770      task-clock (msec)         #    0.992 CPUs utilized          
           281,359      context-switches          #    0.103 K/sec                  
            15,751      cpu-migrations            #    0.006 K/sec                  
           202,230      page-faults               #    0.074 K/sec                  
 6,908,315,514,192      cycles                    #    2.533 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,003,471,450,015      instructions              #    1.88  insns per cycle        
   234,813,483,287      branches                  #   86.086 M/sec                  
     5,137,391,379      branch-misses             #    2.19% of all branches        

    2750.578638572 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.2#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.2#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.3#

               Core t (s)   Wall t (s)        (%)
       Time:     2810.217     2810.217      100.0
                         46:50
                 (ns/day)    (hour/ns)
Performance:        4.612        5.204

GROMACS reminds you: "Microsecond Here I Come" (P.J. Van Maaren)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2787476.705037      task-clock (msec)         #    0.992 CPUs utilized          
           287,232      context-switches          #    0.103 K/sec                  
            16,350      cpu-migrations            #    0.006 K/sec                  
           218,556      page-faults               #    0.078 K/sec                  
 7,074,088,524,944      cycles                    #    2.538 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,617,854,981,669      instructions              #    1.93  insns per cycle        
   264,977,750,034      branches                  #   95.060 M/sec                  
     5,342,425,419      branch-misses             #    2.02% of all branches        

    2810.940092150 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.3#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.3#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.4#

               Core t (s)   Wall t (s)        (%)
       Time:     2751.021     2751.021      100.0
                         45:51
                 (ns/day)    (hour/ns)
Performance:        4.711        5.094

GROMACS reminds you: "Alas, You're Welcome" (Prof. Dumbledore in Potter Puppet Pals)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2728588.065382      task-clock (msec)         #    0.992 CPUs utilized          
           282,305      context-switches          #    0.103 K/sec                  
            15,105      cpu-migrations            #    0.006 K/sec                  
           141,489      page-faults               #    0.052 K/sec                  
 6,916,503,708,608      cycles                    #    2.535 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,139,241,491,299      instructions              #    1.90  insns per cycle        
   241,578,814,982      branches                  #   88.536 M/sec                  
     4,887,429,333      branch-misses             #    2.02% of all branches        

    2751.750823770 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.4#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.4#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.5#

               Core t (s)   Wall t (s)        (%)
       Time:     2758.616     2758.616      100.0
                         45:58
                 (ns/day)    (hour/ns)
Performance:        4.698        5.108

GROMACS reminds you: "Let us not get carried away with our ideas and take our models too seriously" (Nancy Swanson)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2736175.925600      task-clock (msec)         #    0.992 CPUs utilized          
           282,541      context-switches          #    0.103 K/sec                  
            15,491      cpu-migrations            #    0.006 K/sec                  
           295,559      page-faults               #    0.108 K/sec                  
 6,953,828,125,798      cycles                    #    2.541 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,150,170,559,146      instructions              #    1.89  insns per cycle        
   246,734,364,433      branches                  #   90.175 M/sec                  
     5,610,434,192      branch-misses             #    2.27% of all branches        

    2759.409943350 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.5#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.5#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.6#

               Core t (s)   Wall t (s)        (%)
       Time:     2757.265     2757.265      100.0
                         45:57
                 (ns/day)    (hour/ns)
Performance:        4.700        5.106

GROMACS reminds you: "Don't be afraid of hard work. Nothing worthwhile comes easily. Don't let others discourage you or tell you that you can't do it. In my day I was told women didn't go into chemistry. I saw no reason why we couldn't." (Gertrude Elion)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2734690.956374      task-clock (msec)         #    0.992 CPUs utilized          
           282,688      context-switches          #    0.103 K/sec                  
            16,659      cpu-migrations            #    0.006 K/sec                  
           185,791      page-faults               #    0.068 K/sec                  
 6,929,175,764,978      cycles                    #    2.534 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,178,783,508,695      instructions              #    1.90  insns per cycle        
   238,798,672,853      branches                  #   87.322 M/sec                  
     5,114,832,292      branch-misses             #    2.14% of all branches        

    2758.010731309 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.6#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.6#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.7#

               Core t (s)   Wall t (s)        (%)
       Time:     2745.106     2745.106      100.0
                         45:45
                 (ns/day)    (hour/ns)
Performance:        4.721        5.083

GROMACS reminds you: "We Can Dance Like Iggy Pop" (Red Hot Chili Peppers)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2722501.193353      task-clock (msec)         #    0.991 CPUs utilized          
           281,138      context-switches          #    0.103 K/sec                  
            16,969      cpu-migrations            #    0.006 K/sec                  
           218,328      page-faults               #    0.080 K/sec                  
 6,896,223,635,256      cycles                    #    2.533 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,005,668,221,934      instructions              #    1.89  insns per cycle        
   234,567,740,398      branches                  #   86.159 M/sec                  
     5,117,976,869      branch-misses             #    2.18% of all branches        

    2745.851682077 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.7#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.7#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.8#

               Core t (s)   Wall t (s)        (%)
       Time:     2767.498     2767.498      100.0
                         46:07
                 (ns/day)    (hour/ns)
Performance:        4.683        5.125

GROMACS reminds you: "I ought to warn you, I have no faith" (Jane Eyre in Jane Eyre by Charlotte Bronte)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2744883.833628      task-clock (msec)         #    0.992 CPUs utilized          
           282,973      context-switches          #    0.103 K/sec                  
            17,425      cpu-migrations            #    0.006 K/sec                  
           182,292      page-faults               #    0.066 K/sec                  
 6,961,729,598,784      cycles                    #    2.536 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,149,166,347,796      instructions              #    1.89  insns per cycle        
   246,502,807,013      branches                  #   89.804 M/sec                  
     5,621,384,272      branch-misses             #    2.28% of all branches        

    2768.250934943 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.8#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.8#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.9#

               Core t (s)   Wall t (s)        (%)
       Time:     2752.696     2752.696      100.0
                         45:52
                 (ns/day)    (hour/ns)
Performance:        4.708        5.098

GROMACS reminds you: "There's no kill like overkill, right?" (Erik Lindahl)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2730112.603322      task-clock (msec)         #    0.992 CPUs utilized          
           282,621      context-switches          #    0.104 K/sec                  
            16,960      cpu-migrations            #    0.006 K/sec                  
           145,858      page-faults               #    0.053 K/sec                  
 6,917,659,003,042      cycles                    #    2.534 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,171,043,793,486      instructions              #    1.90  insns per cycle        
   237,359,302,833      branches                  #   86.941 M/sec                  
     4,911,740,710      branch-misses             #    2.07% of all branches        

    2753.432578432 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.9#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.9#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.10#

               Core t (s)   Wall t (s)        (%)
       Time:     2743.042     2743.042      100.0
                         45:43
                 (ns/day)    (hour/ns)
Performance:        4.725        5.080

GROMACS reminds you: "This May Come As a Shock" (F. Black)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2720653.985851      task-clock (msec)         #    0.992 CPUs utilized          
           280,752      context-switches          #    0.103 K/sec                  
            16,157      cpu-migrations            #    0.006 K/sec                  
           158,718      page-faults               #    0.058 K/sec                  
 6,900,672,838,869      cycles                    #    2.536 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
12,994,661,150,736      instructions              #    1.88  insns per cycle        
   233,376,170,723      branches                  #   85.779 M/sec                  
     4,933,668,563      branch-misses             #    2.11% of all branches        

    2743.733992576 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.10#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.10#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.11#

               Core t (s)   Wall t (s)        (%)
       Time:     2764.201     2764.201      100.0
                         46:04
                 (ns/day)    (hour/ns)
Performance:        4.689        5.119

GROMACS reminds you: "Art For Arts Sake, Money For Gods Sake" (10 CC)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2741382.770729      task-clock (msec)         #    0.991 CPUs utilized          
           283,422      context-switches          #    0.103 K/sec                  
            15,530      cpu-migrations            #    0.006 K/sec                  
           204,800      page-faults               #    0.075 K/sec                  
 6,931,082,873,210      cycles                    #    2.528 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,195,251,456,495      instructions              #    1.90  insns per cycle        
   239,994,265,373      branches                  #   87.545 M/sec                  
     5,288,125,040      branch-misses             #    2.20% of all branches        

    2764.933356290 seconds time elapsed

                       :-) GROMACS - gmx mdrun, 2016 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2015, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016
Executable:   /opt/packages/gromacs-2016-CPU/bin/gmx_mpi
Data prefix:  /opt/packages/gromacs-2016-CPU
Working dir:  /home/mha/gromacs/run_1
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.11#

Running on 1 node with total 28 cores, 28 logical cores
Hardware detected on host r255.pvt.bridges.psc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


NOTE: Thread affinity setting failed. This can cause performance degradation.
      If you think your settings are correct, ask on the gmx-users list.


Back Off! I just backed up ener.edr to ./#ener.edr.11#
starting mdrun 'Protein in water'
75000 steps,    150.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.12#

               Core t (s)   Wall t (s)        (%)
       Time:     2747.639     2747.639      100.0
                         45:47
                 (ns/day)    (hour/ns)
Performance:        4.717        5.088

GROMACS reminds you: "Give a Man a Fish" (Arrested Development)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

    2725239.062666      task-clock (msec)         #    0.992 CPUs utilized          
           281,162      context-switches          #    0.103 K/sec                  
            16,096      cpu-migrations            #    0.006 K/sec                  
           179,902      page-faults               #    0.066 K/sec                  
 6,907,385,259,452      cycles                    #    2.535 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
13,012,384,507,815      instructions              #    1.88  insns per cycle        
   235,860,242,141      branches                  #   86.547 M/sec                  
     5,319,338,796      branch-misses             #    2.26% of all branches        

    2748.352972259 seconds time elapsed

