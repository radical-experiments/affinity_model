                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

               Core t (s)   Wall t (s)        (%)
       Time:       31.869       31.869      100.0
                 (ns/day)    (hour/ns)
Performance:        5.428        4.422

GROMACS reminds you: "This May Come As a Shock" (F. Black)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32136.018015      task-clock (msec)         #    0.997 CPUs utilized          
             1,892      context-switches          #    0.059 K/sec                  
                 5      cpu-migrations            #    0.000 K/sec                  
            12,486      page-faults               #    0.389 K/sec                  
    89,786,274,522      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,549,323,616      instructions              #    2.37  insns per cycle        
     3,357,980,777      branches                  #  104.493 M/sec                  
        59,520,781      branch-misses             #    1.77% of all branches        

      32.218594607 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.1#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.1#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.1#

               Core t (s)   Wall t (s)        (%)
       Time:       31.834       31.834      100.0
                 (ns/day)    (hour/ns)
Performance:        5.434        4.417

GROMACS reminds you: "Today we're not going to optimize our CUDA code, cause that's just a rabbit hole of misery!" (Tim Warburton)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32095.426325      task-clock (msec)         #    0.997 CPUs utilized          
             1,945      context-switches          #    0.061 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,500      page-faults               #    0.389 K/sec                  
    89,668,657,685      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,726,071,888      instructions              #    2.37  insns per cycle        
     3,354,533,188      branches                  #  104.517 M/sec                  
        59,786,577      branch-misses             #    1.78% of all branches        

      32.182099135 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.2#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.2#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.2#

               Core t (s)   Wall t (s)        (%)
       Time:       32.258       32.258      100.0
                 (ns/day)    (hour/ns)
Performance:        5.362        4.476

GROMACS reminds you: "Scientists do not join hands every Sunday and sing "Yes gravity is real! I know gravity is real! I will have faith! I believe in my heart that what goes up, up, up must come down, down, down. Amen!" If they did, we would think they were pretty insecure about the concept." (Dan Barker)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32516.633610      task-clock (msec)         #    0.997 CPUs utilized          
             1,933      context-switches          #    0.059 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,497      page-faults               #    0.384 K/sec                  
    90,845,857,191      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,669,264,294      instructions              #    2.34  insns per cycle        
     3,353,825,484      branches                  #  103.142 M/sec                  
        59,443,034      branch-misses             #    1.77% of all branches        

      32.604796853 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.3#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.3#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.3#

               Core t (s)   Wall t (s)        (%)
       Time:       31.860       31.860      100.0
                 (ns/day)    (hour/ns)
Performance:        5.429        4.421

GROMACS reminds you: "What's Your Definition Of Dirty ?" (G. Michael)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32121.238651      task-clock (msec)         #    0.997 CPUs utilized          
             1,933      context-switches          #    0.060 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,496      page-faults               #    0.389 K/sec                  
    89,740,858,739      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,643,198,860      instructions              #    2.37  insns per cycle        
     3,358,707,326      branches                  #  104.563 M/sec                  
        59,529,025      branch-misses             #    1.77% of all branches        

      32.206633798 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.4#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.4#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.4#

               Core t (s)   Wall t (s)        (%)
       Time:       32.232       32.232      100.0
                 (ns/day)    (hour/ns)
Performance:        5.367        4.472

GROMACS reminds you: "Load Up Your Rubber Bullets" (10 CC)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32489.064574      task-clock (msec)         #    0.997 CPUs utilized          
             1,948      context-switches          #    0.060 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,495      page-faults               #    0.385 K/sec                  
    90,768,493,844      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,730,165,032      instructions              #    2.34  insns per cycle        
     3,356,353,095      branches                  #  103.307 M/sec                  
        59,568,454      branch-misses             #    1.77% of all branches        

      32.579711731 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.5#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.5#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.5#

               Core t (s)   Wall t (s)        (%)
       Time:       31.810       31.810      100.0
                 (ns/day)    (hour/ns)
Performance:        5.438        4.414

GROMACS reminds you: "Everybody's Good Enough For Some Change" (LIVE)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32068.119369      task-clock (msec)         #    0.997 CPUs utilized          
             1,953      context-switches          #    0.061 K/sec                  
                 3      cpu-migrations            #    0.000 K/sec                  
            12,497      page-faults               #    0.390 K/sec                  
    89,592,328,134      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,625,992,657      instructions              #    2.37  insns per cycle        
     3,353,524,947      branches                  #  104.575 M/sec                  
        59,456,425      branch-misses             #    1.77% of all branches        

      32.156099337 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.6#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.6#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.6#

               Core t (s)   Wall t (s)        (%)
       Time:       31.932       31.932      100.0
                 (ns/day)    (hour/ns)
Performance:        5.417        4.431

GROMACS reminds you: "In the End Science Comes Down to Praying" (P. v.d. Berg)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32196.494523      task-clock (msec)         #    0.997 CPUs utilized          
             1,961      context-switches          #    0.061 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,495      page-faults               #    0.388 K/sec                  
    89,956,095,118      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,835,105,641      instructions              #    2.37  insns per cycle        
     3,357,819,851      branches                  #  104.291 M/sec                  
        59,582,257      branch-misses             #    1.77% of all branches        

      32.283847960 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.7#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.7#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.7#

               Core t (s)   Wall t (s)        (%)
       Time:       32.103       32.103      100.0
                 (ns/day)    (hour/ns)
Performance:        5.388        4.454

GROMACS reminds you: "And It Goes a Little Something Like This" (Tag Team)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32362.474249      task-clock (msec)         #    0.997 CPUs utilized          
             1,979      context-switches          #    0.061 K/sec                  
                 3      cpu-migrations            #    0.000 K/sec                  
            12,495      page-faults               #    0.386 K/sec                  
    90,416,439,868      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,648,514,359      instructions              #    2.35  insns per cycle        
     3,355,466,892      branches                  #  103.684 M/sec                  
        59,412,778      branch-misses             #    1.77% of all branches        

      32.453411267 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.8#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.8#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.8#

               Core t (s)   Wall t (s)        (%)
       Time:       31.911       31.911      100.0
                 (ns/day)    (hour/ns)
Performance:        5.421        4.428

GROMACS reminds you: "Stay Cool, This is a Robbery" (Pulp Fiction)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32170.399813      task-clock (msec)         #    0.997 CPUs utilized          
             1,976      context-switches          #    0.061 K/sec                  
                 2      cpu-migrations            #    0.000 K/sec                  
            12,496      page-faults               #    0.388 K/sec                  
    89,882,918,533      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,709,212,443      instructions              #    2.37  insns per cycle        
     3,360,893,087      branches                  #  104.472 M/sec                  
        59,611,575      branch-misses             #    1.77% of all branches        

      32.260436190 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.9#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.9#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.9#

               Core t (s)   Wall t (s)        (%)
       Time:       31.801       31.801      100.0
                 (ns/day)    (hour/ns)
Performance:        5.439        4.412

GROMACS reminds you: "Throwing the Baby Away With the SPC" (S. Hayward)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32060.747442      task-clock (msec)         #    0.997 CPUs utilized          
             1,981      context-switches          #    0.062 K/sec                  
                 0      cpu-migrations            #    0.000 K/sec                  
            12,499      page-faults               #    0.390 K/sec                  
    89,570,377,805      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,660,547,871      instructions              #    2.37  insns per cycle        
     3,353,628,474      branches                  #  104.602 M/sec                  
        59,532,786      branch-misses             #    1.78% of all branches        

      32.152470848 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.10#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.10#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.10#

               Core t (s)   Wall t (s)        (%)
       Time:       32.159       32.159      100.0
                 (ns/day)    (hour/ns)
Performance:        5.379        4.462

GROMACS reminds you: "One Cross Each" (Monty Python)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32419.666332      task-clock (msec)         #    0.997 CPUs utilized          
             1,991      context-switches          #    0.061 K/sec                  
                 2      cpu-migrations            #    0.000 K/sec                  
            12,495      page-faults               #    0.385 K/sec                  
    90,573,961,325      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,738,404,433      instructions              #    2.35  insns per cycle        
     3,358,123,966      branches                  #  103.583 M/sec                  
        59,573,215      branch-misses             #    1.77% of all branches        

      32.509477890 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.11#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.11#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.11#

               Core t (s)   Wall t (s)        (%)
       Time:       31.875       31.875      100.0
                 (ns/day)    (hour/ns)
Performance:        5.427        4.423

GROMACS reminds you: "History has expired" (PubMed Central)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32136.077754      task-clock (msec)         #    0.997 CPUs utilized          
             1,987      context-switches          #    0.062 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,496      page-faults               #    0.389 K/sec                  
    89,783,192,688      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,677,836,679      instructions              #    2.37  insns per cycle        
     3,357,314,421      branches                  #  104.472 M/sec                  
        59,606,678      branch-misses             #    1.78% of all branches        

      32.226313105 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.12#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.12#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.12#

               Core t (s)   Wall t (s)        (%)
       Time:       31.859       31.859      100.0
                 (ns/day)    (hour/ns)
Performance:        5.429        4.421

GROMACS reminds you: "I Am a Wonderful Thing" (Kid Creole)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32120.130355      task-clock (msec)         #    0.997 CPUs utilized          
             2,007      context-switches          #    0.062 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,497      page-faults               #    0.389 K/sec                  
    89,738,896,568      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,793,626,481      instructions              #    2.37  insns per cycle        
     3,356,994,363      branches                  #  104.514 M/sec                  
        59,529,212      branch-misses             #    1.77% of all branches        

      32.210481274 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.13#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.13#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.13#

               Core t (s)   Wall t (s)        (%)
       Time:       31.785       31.785      100.0
                 (ns/day)    (hour/ns)
Performance:        5.442        4.410

GROMACS reminds you: "With a Little Penknife" (Nick Cave)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32044.306175      task-clock (msec)         #    0.997 CPUs utilized          
             2,001      context-switches          #    0.062 K/sec                  
                 0      cpu-migrations            #    0.000 K/sec                  
            12,496      page-faults               #    0.390 K/sec                  
    89,525,416,835      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,664,715,521      instructions              #    2.38  insns per cycle        
     3,356,287,754      branches                  #  104.739 M/sec                  
        59,419,954      branch-misses             #    1.77% of all branches        

      32.137855523 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_2
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.14#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-13-49.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.14#
starting mdrun 'Protein in water'
1000 steps,      2.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.14#

               Core t (s)   Wall t (s)        (%)
       Time:       31.898       31.898      100.0
                 (ns/day)    (hour/ns)
Performance:        5.423        4.426

GROMACS reminds you: "Our struggle today is not to have a female Einstein get appointed as an assistant professor. It is for a woman schlemiel to get as quickly promoted as a male schlemiel." (Bella Abzug)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

      32160.016420      task-clock (msec)         #    0.997 CPUs utilized          
             2,013      context-switches          #    0.063 K/sec                  
                 5      cpu-migrations            #    0.000 K/sec                  
            12,497      page-faults               #    0.389 K/sec                  
    89,851,761,479      cycles                    #    2.794 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
   212,782,879,533      instructions              #    2.37  insns per cycle        
     3,358,438,361      branches                  #  104.429 M/sec                  
        59,685,115      branch-misses             #    1.78% of all branches        

      32.251040228 seconds time elapsed

