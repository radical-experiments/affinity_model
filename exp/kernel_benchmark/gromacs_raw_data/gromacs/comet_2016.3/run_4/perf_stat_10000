                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.30#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.30#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.30#

               Core t (s)   Wall t (s)        (%)
       Time:      320.078      320.078      100.0
                 (ns/day)    (hour/ns)
Performance:        5.399        4.445

GROMACS reminds you: "If it's a good idea, go ahead and do it. It's much easier to apologize than it is to get permission." (Grace Hopper, developer of COBOL)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     320574.162250      task-clock (msec)         #    1.000 CPUs utilized          
             3,139      context-switches          #    0.010 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,500      page-faults               #    0.039 K/sec                  
   895,436,125,764      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,397,501,158      instructions              #    2.36  insns per cycle        
    31,970,239,249      branches                  #   99.728 M/sec                  
       575,150,153      branch-misses             #    1.80% of all branches        

     320.454249747 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.31#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.31#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.31#

               Core t (s)   Wall t (s)        (%)
       Time:      318.366      318.366      100.0
                 (ns/day)    (hour/ns)
Performance:        5.428        4.421

GROMACS reminds you: "Bad As This Shit Is, This Shit Ain't As Bad As You Think It Is." (Jackie Brown)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     318864.936363      task-clock (msec)         #    1.000 CPUs utilized          
             3,204      context-switches          #    0.010 K/sec                  
                 7      cpu-migrations            #    0.000 K/sec                  
            12,498      page-faults               #    0.039 K/sec                  
   890,678,614,239      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,550,678,763      instructions              #    2.37  insns per cycle        
    31,943,793,038      branches                  #  100.180 M/sec                  
       575,305,414      branch-misses             #    1.80% of all branches        

     318.753321719 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.32#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.32#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.32#

               Core t (s)   Wall t (s)        (%)
       Time:      321.531      321.531      100.0
                 (ns/day)    (hour/ns)
Performance:        5.375        4.465

GROMACS reminds you: "We All Get the Flu, We All Get Aids" (LIVE)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     322032.858305      task-clock (msec)         #    1.000 CPUs utilized          
             3,187      context-switches          #    0.010 K/sec                  
                12      cpu-migrations            #    0.000 K/sec                  
            12,567      page-faults               #    0.039 K/sec                  
   899,501,027,646      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,785,722,485      instructions              #    2.35  insns per cycle        
    31,947,100,782      branches                  #   99.204 M/sec                  
       575,974,269      branch-misses             #    1.80% of all branches        

     321.901847124 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.33#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.33#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.33#

               Core t (s)   Wall t (s)        (%)
       Time:      318.035      318.035      100.0
                 (ns/day)    (hour/ns)
Performance:        5.434        4.417

GROMACS reminds you: "Engage" (J.L. Picard)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     318532.431693      task-clock (msec)         #    1.000 CPUs utilized          
             3,189      context-switches          #    0.010 K/sec                  
                 5      cpu-migrations            #    0.000 K/sec                  
            12,634      page-faults               #    0.040 K/sec                  
   889,726,030,270      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,727,852,526      instructions              #    2.37  insns per cycle        
    31,961,679,020      branches                  #  100.340 M/sec                  
       575,308,842      branch-misses             #    1.80% of all branches        

     318.399604862 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.34#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.34#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.34#

               Core t (s)   Wall t (s)        (%)
       Time:      317.399      317.399      100.0
                 (ns/day)    (hour/ns)
Performance:        5.445        4.408

GROMACS reminds you: "Naive you are if you believe life favours those who aren't naive." (Piet Hein)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     317894.172567      task-clock (msec)         #    1.000 CPUs utilized          
             3,164      context-switches          #    0.010 K/sec                  
                 4      cpu-migrations            #    0.000 K/sec                  
            12,634      page-faults               #    0.040 K/sec                  
   887,937,171,874      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,729,435,682      instructions              #    2.38  insns per cycle        
    31,970,537,971      branches                  #  100.570 M/sec                  
       575,658,629      branch-misses             #    1.80% of all branches        

     317.763956221 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.35#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.35#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.35#

               Core t (s)   Wall t (s)        (%)
       Time:      321.904      321.904      100.0
                 (ns/day)    (hour/ns)
Performance:        5.369        4.470

GROMACS reminds you: "The first 90% of the code accounts for the first 90% of the development time. The remaining 10% of the code accounts for the other 90% of the development time." (Tom Cargill)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     322405.514220      task-clock (msec)         #    1.000 CPUs utilized          
             3,197      context-switches          #    0.010 K/sec                  
                 3      cpu-migrations            #    0.000 K/sec                  
            12,635      page-faults               #    0.039 K/sec                  
   900,557,946,162      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,620,368,721      instructions              #    2.34  insns per cycle        
    31,966,115,388      branches                  #   99.149 M/sec                  
       577,372,567      branch-misses             #    1.81% of all branches        

     322.271063355 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.36#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.36#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.36#

               Core t (s)   Wall t (s)        (%)
       Time:      318.420      318.420      100.0
                 (ns/day)    (hour/ns)
Performance:        5.427        4.422

GROMACS reminds you: "Documentation is like sex: When it's good it's great, and when it's bad it's better than nothing." (Linus Torvalds)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     318917.794133      task-clock (msec)         #    1.000 CPUs utilized          
             3,185      context-switches          #    0.010 K/sec                  
                 4      cpu-migrations            #    0.000 K/sec                  
            12,631      page-faults               #    0.040 K/sec                  
   890,828,902,437      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,110,804,125,994      instructions              #    2.37  insns per cycle        
    31,857,344,251      branches                  #   99.892 M/sec                  
       567,143,059      branch-misses             #    1.78% of all branches        

     318.787360417 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.37#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.37#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.37#

               Core t (s)   Wall t (s)        (%)
       Time:      318.705      318.705      100.0
                 (ns/day)    (hour/ns)
Performance:        5.422        4.426

GROMACS reminds you: "There's Still Time to Change the Road You're On" (Led Zeppelin)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     319200.884730      task-clock (msec)         #    1.000 CPUs utilized          
             3,210      context-switches          #    0.010 K/sec                  
                 3      cpu-migrations            #    0.000 K/sec                  
            12,633      page-faults               #    0.040 K/sec                  
   891,590,812,728      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,418,211,970      instructions              #    2.37  insns per cycle        
    31,970,948,552      branches                  #  100.159 M/sec                  
       574,950,015      branch-misses             #    1.80% of all branches        

     319.070346252 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.38#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.38#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.38#

               Core t (s)   Wall t (s)        (%)
       Time:      318.317      318.317      100.0
                 (ns/day)    (hour/ns)
Performance:        5.429        4.421

GROMACS reminds you: "There's no way you can rely on an experiment" (Gerrit Groenhof)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     318808.389129      task-clock (msec)         #    1.000 CPUs utilized          
             3,229      context-switches          #    0.010 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,496      page-faults               #    0.039 K/sec                  
   890,501,900,033      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,428,889,376      instructions              #    2.37  insns per cycle        
    31,943,586,006      branches                  #  100.197 M/sec                  
       575,361,962      branch-misses             #    1.80% of all branches        

     318.684900287 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.39#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.39#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.39#

               Core t (s)   Wall t (s)        (%)
       Time:      318.066      318.066      100.0
                 (ns/day)    (hour/ns)
Performance:        5.433        4.417

GROMACS reminds you: "If You See Me Getting High, Knock Me Down" (Red Hot Chili Peppers)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     318561.029146      task-clock (msec)         #    1.000 CPUs utilized          
             3,211      context-switches          #    0.010 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,497      page-faults               #    0.039 K/sec                  
   889,800,996,957      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,857,024,829      instructions              #    2.37  insns per cycle        
    31,960,132,090      branches                  #  100.327 M/sec                  
       575,334,591      branch-misses             #    1.80% of all branches        

     318.434263685 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.40#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.40#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.40#

               Core t (s)   Wall t (s)        (%)
       Time:      319.473      319.473      100.0
                 (ns/day)    (hour/ns)
Performance:        5.409        4.437

GROMACS reminds you: "Perl: The only language that looks the same before and after RSA encryption." (Keith Bostic)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     319966.796130      task-clock (msec)         #    1.000 CPUs utilized          
             3,339      context-switches          #    0.010 K/sec                  
                16      cpu-migrations            #    0.000 K/sec                  
            12,500      page-faults               #    0.039 K/sec                  
   893,720,163,188      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,309,500,000      instructions              #    2.36  insns per cycle        
    31,984,741,857      branches                  #   99.963 M/sec                  
       576,600,284      branch-misses             #    1.80% of all branches        

     319.840923336 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.41#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.41#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.41#

               Core t (s)   Wall t (s)        (%)
       Time:      321.767      321.767      100.0
                 (ns/day)    (hour/ns)
Performance:        5.371        4.469

GROMACS reminds you: "I'll Master Your Language, and In the Meantime I'll Create My Own" (Tricky)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     322268.170478      task-clock (msec)         #    1.000 CPUs utilized          
             3,226      context-switches          #    0.010 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,499      page-faults               #    0.039 K/sec                  
   900,176,096,035      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,546,097,075      instructions              #    2.35  insns per cycle        
    31,960,196,923      branches                  #   99.173 M/sec                  
       575,142,254      branch-misses             #    1.80% of all branches        

     322.134848384 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.42#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.42#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.42#

               Core t (s)   Wall t (s)        (%)
       Time:      320.124      320.124      100.0
                 (ns/day)    (hour/ns)
Performance:        5.398        4.446

GROMACS reminds you: "If You Want Something Done You Have to Do It Yourself" (Highlander II)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     320617.068953      task-clock (msec)         #    1.000 CPUs utilized          
             3,261      context-switches          #    0.010 K/sec                  
                 0      cpu-migrations            #    0.000 K/sec                  
            12,498      page-faults               #    0.039 K/sec                  
   895,554,155,290      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,206,701,974      instructions              #    2.36  insns per cycle        
    31,943,486,870      branches                  #   99.631 M/sec                  
       576,781,258      branch-misses             #    1.81% of all branches        

     320.493707703 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.43#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.43#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.43#

               Core t (s)   Wall t (s)        (%)
       Time:      317.535      317.535      100.0
                 (ns/day)    (hour/ns)
Performance:        5.442        4.410

GROMACS reminds you: "Blessed is He Who In the Name Of Charity and Good Will Shepherds the Weak Through the Valley Of Darkness, For He is Truly His Brother's Keeper and the Finder Of Lost Children." (Pulp Fiction)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     318029.252023      task-clock (msec)         #    1.000 CPUs utilized          
             3,230      context-switches          #    0.010 K/sec                  
                14      cpu-migrations            #    0.000 K/sec                  
            12,496      page-faults               #    0.039 K/sec                  
   888,321,538,273      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,207,565,110      instructions              #    2.38  insns per cycle        
    31,956,698,324      branches                  #  100.484 M/sec                  
       575,349,798      branch-misses             #    1.80% of all branches        

     317.903584089 seconds time elapsed

                      :-) GROMACS - gmx mdrun, 2016.3 (-:

                            GROMACS is written by:
     Emile Apol      Rossen Apostolov  Herman J.C. Berendsen    Par Bjelkmar   
 Aldert van Buuren   Rudi van Drunen     Anton Feenstra    Gerrit Groenhof  
 Christoph Junghans   Anca Hamuraru    Vincent Hindriksen Dimitrios Karkoulis
    Peter Kasson        Jiri Kraus      Carsten Kutzner      Per Larsson    
  Justin A. Lemkul   Magnus Lundborg   Pieter Meulenhoff    Erik Marklund   
   Teemu Murtola       Szilard Pall       Sander Pronk      Roland Schulz   
  Alexey Shvetsov     Michael Shirts     Alfons Sijbers     Peter Tieleman  
  Teemu Virolainen  Christian Wennberg    Maarten Wolf   
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2017, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2016.3
Executable:   /opt/gromacs/bin/gmx_mpi
Data prefix:  /opt/gromacs
Working dir:  /home/mingtha/gromacs/v2016.3/run_4
Command line:
  gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro


Back Off! I just backed up md.log to ./#md.log.44#

NOTE: Error occurred during GPU detection:
      CUDA driver version is insufficient for CUDA runtime version
      Can not use GPU acceleration, will fall back to CPU kernels.


Running on 1 node with total 24 cores, 24 logical cores, 0 compatible GPUs
Hardware detected on host comet-17-04.sdsc.edu (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
    SIMD instructions most likely to fit this hardware: AVX2_256
    SIMD instructions selected at GROMACS compile time: AVX2_256

  Hardware topology: Full, with devices

Reading file out.tpr, VERSION 2016.3 (single precision)
Using 1 MPI process
Using 1 OpenMP thread 


Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up ener.edr to ./#ener.edr.44#
starting mdrun 'Protein in water'
10000 steps,     20.0 ps.

Writing final coordinates.

Back Off! I just backed up out.gro to ./#out.gro.44#

               Core t (s)   Wall t (s)        (%)
       Time:      317.375      317.375      100.0
                 (ns/day)    (hour/ns)
Performance:        5.445        4.408

GROMACS reminds you: "I am at two with nature." (Woody Allen)


 Performance counter stats for 'gmx_mpi mdrun -ntomp 1 -s out.tpr -c out.gro':

     317866.378089      task-clock (msec)         #    1.000 CPUs utilized          
             3,244      context-switches          #    0.010 K/sec                  
                 1      cpu-migrations            #    0.000 K/sec                  
            12,634      page-faults               #    0.040 K/sec                  
   887,870,465,851      cycles                    #    2.793 GHz                    
   <not supported>      stalled-cycles-frontend  
   <not supported>      stalled-cycles-backend   
 2,111,524,869,342      instructions              #    2.38  insns per cycle        
    31,959,210,148      branches                  #  100.543 M/sec                  
       575,352,441      branch-misses             #    1.80% of all branches        

     317.742574513 seconds time elapsed

